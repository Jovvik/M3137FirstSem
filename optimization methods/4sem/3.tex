\chapter{24 февраля}

\subsection{Метод равномерного перебора}

\begin{itemize}
    \item [Шаг 1:] Если \(f(x_0) > f(x_0 + \delta)\), то \(k = 1, x_1 = x_0 + \delta, h = \delta\)

          иначе \(x_1 = x_0, h = - \delta\)

    \item [Шаг 2:] \(h = 2h, x_{k+1} = x_k + h\)
    \item [Шаг 3:] Если \(f(x_k) > f(x_{k+1})\), то \(k = k + 1\) и переходим к шагу 2. Иначе прекращаем поиск и искомое лежит в \([x_{k - 1}, x_{k + 1}]\)
\end{itemize}

\section{Методы оптимизации, использующие производную}

В рамках этой главы \(f(x)\) --- дифференцируемая или дважды дифференцируемая выпуклая функция.

Есть три классических метода, использующих производную:
\begin{itemize}
    \item Средней точки
    \item Метод хорд
    \item Метод Ньютона
\end{itemize}

\(f'(x) = 0\) --- необходимое и достаточное условие глобального минимума. Таким образом, условие остановки вычислений --- \(f'(x) \approx 0\), т.е. \(|f'(x)| \leq \varepsilon\)

\subsection{Методы средней точки}

Средняя точка \(\overline x = \frac{a + b}{2}\).

Общая идея алгоритма:
\begin{itemize}
    \item Если \(f'(x) > 0\), то \(\overline x\in\) участку монотонного возрастания \(f(x)\) и \(x^* < \overline x\), т.е. минимум лежит на \([a, \overline x]\)
    \item Если \(f'(x) < 0\), то аналогично можем вывести, что минимум лежит на \([\overline x, b]\)
    \item Если \(f'(x) = 0\), то мы нашли решение.
\end{itemize}

Перепишем это в виде алгоритма:

\begin{itemize}
    \item [Шаг 1:] \(\overline x = \frac{a + b}{2}\), вычислим \(f'(\overline x)\)
    \item [Шаг 2:] Если \(|f'(x)| \leq \varepsilon\), то \(x^* = \overline x\) и завершаем вычисление.
    \item [Шаг 3:] Сравниваем \(f'(x)\) с нулём: \begin{itemize}
              \item Если \(f'(x) > 0\), то \(x^*\in[a, \overline x]\) и \(b = \overline x\)
              \item Иначе \(x^*\in[\overline x, b]\) и \(a = \overline x\)
          \end{itemize}
\end{itemize}

Длина отрезка после \(n\) итераций есть \(\Delta_n = \frac{b - a}{2^n}\)

\subsection{Метод хорд \textit{(метод секущей)}}

Если \(\exists f'(x)\) на \([a, b]\), \(f'(a) \cdot f'(b) < 0\) и \(f'(x)\) непрерывна на \([a, b]\), то \(\exists x\in(a, b) : f'(x) = 0\).

\(F(x) = f'(x)\). Пусть \(\tilde{x}\) --- точка пересечения хорды \(F(x)\) с осью \(Ox\) на \([a, b]\)

\begin{figure}[h]
    \centering
    \includesvg[scale=0.9]{images/хорда.svg}
\end{figure}

Можем тривиально вывести \(\tilde{x}\) из уравнения прямой по двум точками:
\begin{equation}
    \tilde{x} = a - \frac{f'(a)}{f'(a) - f'(b)}(a - b) \label{пересечение хорды}
\end{equation}

\begin{itemize}
    \item [Шаг 1:] Считаем \(\tilde{x}\) по \eqref{пересечение хорды}
    \item [Шаг 2:] Если \(|f'(\tilde{x})| \leq \varepsilon\), то \(x^* = \tilde{x}\) и мы заканчиваем вычисление.

          Иначе шаг 3.
    \item [Шаг 3:] Переходим к новому отрезку:
          \begin{itemize}
              \item Если \(f'(\tilde{x}) > 0\), то \(x^* \in [a, \tilde{x}], b = \tilde{x}, f'(b) = f'(\tilde{x})\), переходим к шагу 1
              \item иначе \(x^* \in [\tilde{x}, b], a = \tilde{x}, f'(a) = f'(\tilde{x})\), переходим к шагу 1
          \end{itemize}
\end{itemize}

\begin{remark}
    Если \(f'(a) \cdot f'(b) \geq 0\), то \(x^* = a\) или \(x^* = b\).
\end{remark}

\subsection{Метод Ньютона \textit{(метод касательной)}}

Если \(f\) выпуклая на \([a, b]\) и дважды непрерывно дифференцируемая, то уравнение \(f'(x) = 0\) решается методом Ньютона.

Пусть \(x_0 \in [a, b]\) --- начальное приближение \(x^*\). \(F(x) = f'(x)\) линеаризуема в окрестности \(x_0\), т.е.
\begin{equation}
    F(x) \approx F(x_0) + F'(x_0)(x - x_0)
\end{equation}

Пусть \(x_1\) --- следующее приближение к \(x^*\). Это будет пересечение касательной с \(Ox\). Найдём эту точку.

\begin{align*}
    F(x_0) + F'(x_0) (x_1 - x_0) & = 0                            \\
    x_1                          & = x_0 - \frac{F(x_0)}{F'(x_0)}
\end{align*}

Таким образом, мы можем получить \(\{x_k\}_{k = 1}^{n}\) --- итерационную последовательность.

\[x_{k+1} = x_k - \frac{f'(x_k)}{f''(x_k)} \]

Условие остановки такое же, как в предыдущих методах: \(|f'(x_k)| \leq \varepsilon\)
