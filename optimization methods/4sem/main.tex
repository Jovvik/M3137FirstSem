\documentclass[12pt, a4paper, oneside]{book}

\usepackage{catchfilebetweentags}
\ExecuteMetaData[../../preamble.sty]{preamble}

\addto\captionsrussian{\renewcommand{\chaptername}{Лекция}}

\let\MakeUppercase\relax

\lfoot{}
\cfoot{}
\rfoot{}
\lhead{\leftmark}

\usepackage{tocloft}
\advance\cftsecnumwidth -1em\relax
\advance\cftsubsecindent -1em\relax
\advance\cftsubsecnumwidth -1em\relax

\usepackage{titletoc}
\titlecontents*{chapter}% <section-type>
  [0pt]% <left>
  {}% <above-code>
  {\bfseries\chaptername\ \thecontentslabel\quad}% <numbered-entry-format>
  {}% <numberless-entry-format>
  {\bfseries\hfill\contentspage}% <filler-page-format>

\let\endtitlepage\relax

\patchcmd{\chapter}{\thispagestyle{plain}}{\thispagestyle{fancy}}{}{}

\usepackage{remreset}
\makeatletter
  \@removefromreset{section}{chapter}
\makeatother

\usepackage{chngcntr}
\counterwithout{equation}{chapter}

\renewcommand{\thesection}{\arabic{section}}

\begin{document}

\title{Методы оптимизации}
\author{Михайлов Максим}

\maketitle

\tableofcontents

\chapter{10 февраля}

Этот курс --- о минимизации \textit{(максимизации)} функционалов. Кроме конкретных методов оптимизации, планируется рассмотреть форматы хранения матриц, о методах работы с ними и рассмотреть 1-2 \textit{(может быть 3)} СЛАУ с использованием различных форматов.

Т.к. значения, получаемые компьютерами --- не точные, нам требуется теория погрешности.

\section{Теория погрешности}

Все погрешности разделяются на два класса:

\begin{enumerate}
    \item Неустранимая --- обусловлена неточностью исходных данных. Например, неточное знание физических констант или других параметров задачи. Тем не менее, необходимо знать эту погрешность, чтобы ставить рамки погрешности для решения.
    \item Устранимая --- погрешность процесса решения задачи. Эту погрешность можно уменьшить выбором метода решения задачи.
          \begin{enumerate}
              \item Погрешность модели
              \item Остаточная погрешность \textit{(погрешность аппроксимации)}

                    Например, аппроксимация ряда первыми \(n\) его членами или аппроксимация по теореме Вейерштрасса квадратичной функцией.

              \item Погрешность округления \label{округления}
              \item Накапливаемая погрешность \label{накапливаемая}
          \end{enumerate}

          \ref{округления} и \ref{накапливаемая} часто объединяют в вычислительную погрешность.
\end{enumerate}

\begin{definition}
    Пусть \(X^*\) --- точное решение, а \(X\) --- найденное \textit{(приближенное)} решение. Тогда \(X^* - X\) называется \textbf{погрешностью}, а её модуль \(\Delta X = |X^* - X|\) --- \textbf{абсолютная погрешность}.
\end{definition}

Разумеется, \(\Delta X\) представляет сугубо теоретический интерес, т.к. \(X^*\) неизвестна и \(\Delta X\) нельзя вычислить.

\begin{definition}
    В качестве требования к решению часто предоставляется \textbf{предельная абсолютная погрешность} \(\Delta_X \geq |X^* - X|\).
\end{definition}

\begin{definition}
    Также существует \textbf{относительная погрешность} \(\delta X = \left|\cfrac{X^* - X}{|X|}\right|\)
\end{definition}

Относительная погрешность позволяет выражать погрешность относительно значений самой величины. Например, при измерении длины парты погрешность 1 см не очень хорошо, а при измерении расстояния между городами --- приемлемо.

\begin{definition}
    \textbf{Предельная относительная погрешность} \(\delta_X \geq \left|\cfrac{X^* - X}{|X|}\right|\)
\end{definition}

\begin{definition}
    \textbf{Значащие цифры} некоторого числа --- все цифры в его изображении, отличные от нуля, а также нули, если они содержатся между значащими цифрами или расположены в конце числа и указывают на сохранение разряда точности.
\end{definition}

\begin{definition}
    Если значащая цифра приближенного значения \(a\), находящаяся в разряде, в котором выполняется условие \(\Delta \leq 0.5 \cdot 10^k\), т.е. абсолютное значение погрешности не превосходит половину единицы этого разряда \textit{(\(k\) --- номер этого разряда)}, то такая цифра называется \textbf{верной в узком смысле}.

    Цифра называется \textbf{верной в широком смысле}, если в определении выше используется \(1\) вместо \(0.5\).
\end{definition}

\begin{example}
    \(a = 3.635, \Delta a = 0.003\)
    \begin{itemize}
        \item \(k = 0 \quad \frac{1}{2} \cdot 10^0 = \frac{1}{2} \geq \Delta a\)
        \item \(k = - 1 \quad \frac{1}{2} \cdot 10^{ - 1} = 0.05 \geq \Delta a\)
        \item \(k = - 2 \quad \frac{1}{2} \cdot 10^{ - 2} = 0.005 \geq \Delta a\)
        \item \(k = - 3 \quad \frac{1}{2} \cdot 10^{ - 3} = 0.0005 < \Delta a\)
    \end{itemize}

    Таким образом, цифра \(5\) является сомнительной, остальные --- верные.
\end{example}

\begin{example}
    Рассмотрим следующие способы записи одного и того же выражения:
    \[\left( \frac{\sqrt{2} - 1}{\sqrt{2} + 1}  \right)^3 = (\sqrt{2} - 1)^6 = (3 - 2\sqrt{2})^3 = 99 - 70\sqrt{2}\]

    Посчитаем все выражения с различными приближениями \(\sqrt{2}\):

    \begin{itemize}
        \item \(\frac{7}{5} = 1.4\)
        \item \(\frac{17}{12} = 1.41666\)
        \item \(\frac{707}{500} = 1.414\)
        \item \(\sqrt{2} = 1.4142135624\)
    \end{itemize}

    \begin{center}\bgroup\def\arraystretch{1.5}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            \(\sqrt{2}\)        & \(\left( \frac{\sqrt{2} - 1}{\sqrt{2} + 1}  \right)^3\)     & \((\sqrt{2} - 1)^6\)                                                      & \((3 - 2\sqrt{2})^3\)                                    & \(99 - 70\sqrt{2}\)           \\ \hline
            \(\frac{7}{5}\)     & \(\frac{1}{216}\approx 0.00 \underline 4 6\)                & \(\frac{64}{15625}\approx 0.00\underline 51\)                             & \(\frac{1}{125} = 0.008\)                                & \(1\)                         \\ \hline
            \(\frac{17}{12}\)   & \(\frac{125}{24389}\approx 0.00\underline{51}3\)            & \(\frac{15625}{2985354}\approx 0.00\underline52\)                         & \(\frac{1}{216}\approx 0.00\underline46\)                & \( - \frac{1}{6} = - 0.6(6)\) \\ \hline
            \(\frac{707}{500}\) & \(\frac{8869743}{1758416743} \approx 0.00\underline{50}44\) & \(\frac{78672340886049}{15625\cdot 10^{12}} \approx 0.00\underline{50}4\) & \(\frac{636056}{125000000} \approx 0.00\underline{50}9\) & \(0.02\)                      \\ \hline
        \end{tabular}
        \egroup
    \end{center}
\end{example}

\[\Delta_{(X \pm Y)} = \Delta_X + \Delta_Y\]
\[\Delta_{(X\cdot Y)} \approx |Y|\Delta_X + |X|\Delta_Y\]
\[\Delta_{(X / Y)} \approx \left|\frac{1}{Y}\right| \Delta_X + \left|\frac{X}{Y^2}\right| \Delta_Y\]
\[|\Delta u| = |f(x_1 + \Delta x_1, \dots , x_n + \Delta x_n) - f(x_1 \dots x_n)|\]
\[|\Delta u| \approx |df(x_1 \dots x_n)| = \left|\sum_{i = 1}^n \frac{\partial u}{\partial x_i} \Delta x_i\right| \leq \sum_{i = 1}^n \left|\frac{\partial u}{\partial x_i}\right| |\Delta x_i|\]
\[\Delta_u = \sum_{i = 1}^n \left|\frac{\partial u}{\partial x_i}\right| \Delta x_i\]
\[|\delta u| = \sum_{i = 1}^n \left|\frac{\partial \ln u}{\partial x_i}\right||\Delta x_i|\]
\[\delta_u = \sum_{i = 1}^n \left|\frac{\partial \ln u}{\partial x_i}\right||\Delta x_i|\]
\[\delta_{(X \pm Y)} = \left|\frac{X}{X \pm Y}\right|\delta_X + \left|\frac{Y}{X \pm Y}\right|\delta_Y\]
\[\delta_{(X\cdot Y)} = \delta_X + \delta_Y\]
\[\delta_{(X / Y)} = \delta_X + \delta_Y\]

Вернемся к прошлому примеру и посчитаем относительную погрешность.

\(\sphericalangle x = \frac{7}{5}\)

\[\delta_{f_1} = 3 \left|\frac{1}{x - 1} - \frac{1}{x + 1}\right| \cdot |\delta x| = 6.25 |\delta x|\]
\[\delta_{f_2} = 6 \left|\frac{1}{x - 1}\right| \cdot |\delta x| = 15 |\delta x|\]
\[\delta_{f_3} = 6 \left|\frac{1}{3 - 2x}\right| \cdot |\delta x| = 30 |\delta x|\]
\[\delta_{f_4} = \left|\frac{90}{99 - 70x}\right| \cdot |\delta x| = 70 |\delta x|\]

Таким образом, наибольшую погрешность даёт \(f_4\), наименьшую --- \(f_1\).

\begin{example}
    \[y^2 - 140y + 1 = 0\]
    \[y = 70 - \sqrt{4899}\]
    \[\sqrt{4899}\approx 69.99\]
    \[y\approx 70 - 69.99 = 0.0\underline 1\]
    Посчитаем другим методом --- избавимся от вычитания похожих чисел.
    \[y = \frac{1}{70 + \sqrt{4899}}\]
    \[y = \frac{1}{139.99}\approx \frac{1}{140} = 0.00714285 \approx 0.00\underline{7143}\]

    Можно заметить, что результат весьма точнее.
\end{example}

\begin{example}
    Рассмотрим задачу вычисления суммы \(S = \sum_{j = 1}^{10^6} \frac{1}{j^2}\).

    Если суммировать по формуле \(S_n = S_{n - 1} + \frac{1}{n^2}\), то из-за того, что сначала суммируются большие числа, а потом малые, погрешность велика: \(\Delta = 10^6 \cdot 2^{ - 1}\approx 2\cdot 10^{ - 4}\)

    Если же суммировать с конца, то \(\Delta = \mathcal{O}\left( \frac{1}{n} \right) \approx 6\cdot 10^{ - 8}\)
\end{example}

Рекомендации для увеличения точности вычислений:
\begin{enumerate}
    \item Если складывать или вычитать последовательность чисел, то лучше начинать с малых членов. % uwu (поздравляю, вы нашли пасхалку)
    \item Желательно избавляться от вычитания двух почти равных чисел, по возможности преобразую формулу.
    \item Необходимо сводить к минимуму число математических операций. Это также способствует ускорению работы алгоритма.
    \item Если ЯП и компьютер позволяют использовать числа разных типов, то числа с большим числом разрядов всегда повышают точность вычислений \textit{(в ущерб памяти)}. % спасибо, кэп
\end{enumerate}

Дробные числа нужно сравнивать с помощью \(\varepsilon\), т.е. \(|a - b| \leq \varepsilon\)

\section{Задачи оптимизации. Вводное.}

Здесь и далее \textbf{целевая функция} --- функция, которую мы минимизируем.

\begin{obozn}
    Пусть целевая функция --- \(f(x)\). Это обозначается как \(f(x) \xrightarrow{x\in U} \min\).

    \(f(x) \to \max \Rightarrow - f(x) \to \min\). Таким образом, мы без потери общности рассматриваем задачу минимизации.
\end{obozn}

\begin{definition}
    Если \(\exists x^* \in U \ \ f(x^*) \leq f(x) \ \ \forall x\in U\), то такой \(x^*\) называется \textbf{точкой \textit{(глобального)} минимума}
\end{definition}

\begin{obozn}
    Множество всех точек минимума обозначается \(U^* = \{x^*_i\ |\ i = 1\dots k\} \)
\end{obozn}

Мы рассматриваем класс функций таких, что \(U^* \neq \emptyset\)

\begin{definition}
    Функция \(f(x)\) называется \textbf{унимодальной} на \([a, b]\), если она:
    \begin{enumerate}
        \item Непрерывна на \([a, b]\)
        \item \(\exists \alpha, \beta : a \leq \alpha \leq \beta \leq b\), такие что:
              \begin{enumerate}
                  \item Если \(a < \alpha\), то на \([a, \alpha] \quad f(x)\) строго монотонно убывает.
                  \item Если \(\beta < b\), то на \([\beta, b] \quad f(x)\) строго монотонно возрастает.
                  \item \(\forall x\in [\alpha, \beta] \ \ f(x) = f_* = \min\limits_{[a, b]} f(x)\)
              \end{enumerate}
    \end{enumerate}
\end{definition}

\begin{figure}[h]
    \centering
    \begin{minipage}{0.5\textwidth}
        \centering
        \includesvg[width=.9\linewidth]{images/вырожденная_унимодальная.svg}
        \caption{Вырожденные \(\alpha\) и \(\beta\), унимодальная функция}
    \end{minipage}%
    \begin{minipage}{0.5\textwidth}
        \centering
        \includesvg[width=.9\linewidth]{images/не_вырожденная_унимодальная.svg}
        \caption{Унимодальная функция}
    \end{minipage}
\end{figure}

\begin{prop}\itemfix
    \begin{enumerate}
        \item Если функция унимодальна на \([a, b]\), то она унимодальна и на \([c, d] \subset [a, b]\)
        \item Если \(f\) унимодальна на \([a, b], a \leq x_1 < x_2 \leq b\), тогда:
              \begin{enumerate}
                  \item Если \(f(x_1) \leq f(x_2)\), то \(x^*\in [a, x_2]\)
                  \item Если \(f(x_1) > f(x_2)\), то \(x^*\in[x_1, b]\)
              \end{enumerate}
    \end{enumerate}
\end{prop}

\begin{definition}
    \(f(x)\), заданная на \([a, b]\), называется выпуклой на этом отрезке, если
    \[\forall x', x''\in [a, b], \alpha\in[0,1] \quad f(\alpha x' + (1 - \alpha)x'') \leq \alpha f(x') + (1 - \alpha)f(x'')\]
\end{definition}

\begin{prop}\itemfix
    \begin{enumerate}
        \item Если \(f(x)\) выпукло на \([a, b]\), то \(\forall [x', x''] \subset [a, b]\), то её график расположен ниже хорды между \(x'\) и \(x''\)
        \item Всякая выпуклая функция на отрезке является унимодальной на нём.
    \end{enumerate}
\end{prop}

\begin{definition}
    \textbf{Стационарные точки} --- точки \(x\), для которых \(f'(x) = 0\).
\end{definition}

Мы будем рассматривать одномерные задачи оптимизации, т.к. многомерные задачи часто сводятся к одномерным.

\section{Одномерная минимизация функций. Прямые методы.}

Прямые методы --- методы, не использующие производные целевой функции.

\subsection{Метод дихотомии}

Этот метод --- тернарный поиск.

\[x_1 = \frac{b + a - \delta}{2} \quad x_2 = \frac{b + a + \delta}{2}\]
\[\tau = \frac{b - x_1}{b - a} = \frac{x_2 - a}{b - a} \to \frac{1}{2}\]
\[x^* \in [a_i, b_i] \ \ \forall i\]

\begin{itemize}
    \item [Шаг 1:] Находим \(x_1\) и \(x_2\), вычисляем \(f(x_1)\) и \(f(x_2)\)
    \item [Шаг 2:] Сравниваем \(f(x_1)\) и \(f(x_2)\).
          \begin{itemize}
              \item Если \(f(x_1) \leq f(x_2)\), переходим к отрезку \([a, x_2]\), т.е. \(b = x_2\)
              \item Иначе переходим к \([x_1, b]\), т.е. \(a = x_1\)
          \end{itemize}
    \item [Шаг 3:] \(\varepsilon_n = \frac{b - a}{2} \), где \(n\) --- номер итерации.
          \begin{itemize}
              \item Если \(\varepsilon_n > \varepsilon\), переходим к новой итерации.
              \item Если \(\varepsilon_n \leq \varepsilon\), завершаем поиск и переходим к шагу 4.
          \end{itemize}
    \item [Шаг 4:] \(X^* \approx \overline X = \frac{a + b}{2}\)
\end{itemize}

\begin{remark}
    \(\delta\) выбирается на интервале \((0, 2\varepsilon)\). Чем меньше \(\delta\), тем больше относительное уменьшение длины отрезка на каждой итерации. При черезмерно малом \(\delta\) сравнение \(f(x_1)\) и \(f(x_2)\) будет затруднительно, т.к. они близки.
\end{remark}

Мы можем оценить число необходимых итераций:
\[n \geq \log_2 \frac{b - a - \delta}{2\varepsilon - \delta}\]

\chapter{17 февраля}

\subsection{Метод золотого сечения}

Рассмотрим отрезок \([0, 1]\). Пусть \(x_2 = \tau\), тогда симметрично расположенная \(x_1 = 1 - \tau\). Пусть дальше был выбран отрезок \([0, \tau]\), тогда пусть \(x_2' = 1 - \tau\). Чтобы новые точки делили отрезок в таком же соотношении, необходимо, чтобы \(\frac{1}{\tau} = \frac{\tau}{1 - \tau} \Rightarrow \tau^2 = 1 - \tau \Rightarrow \tau = \frac{\sqrt{5} - 1}{2} \approx 0.61803\). Таким образом, \(x_1 = 1 - \tau = \frac{3 - \sqrt{5}}{2}, x_2 = \tau = \frac{\sqrt{5} - 1}{2}\)

В общем случае для отрезка \([a, b]\):
\begin{equation}
    x_1 = a + \frac{3 - \sqrt{5}}{2}(b - a), x_2 = a + \frac{\sqrt{5} - 1}{2} (b - a) \label{x_1, x_2, метод золотого сечения}
\end{equation}

Вычислим погрешность:
\[\Delta_n = \tau^n (b - a) \quad \varepsilon_n = \frac{\Delta_n}{2} = \frac{1}{2}\left( \frac{\sqrt{5} - 1}{2} \right)^n (b - a)\]

Для заданного \(\varepsilon\) условия окончания \(\varepsilon_n \leq \varepsilon\).

Результат метода:
\[x^* = \frac{a_{(n)} + b_{(n)}}{2}\]

Оценка числа шагов для достижения искомой точности:
\[n \geq \ln\left( \frac{\frac{2\varepsilon}{b - a}}{\ln \tau} \right) \approx 2 \cdot 1 \cdot \ln\left( \frac{b - a}{2\varepsilon} \right)\]

\begin{itemize}
    \item [Шаг 1:] Находим \(x_1\) и \(x_2\) по формуле \eqref{x_1, x_2, метод золотого сечения}, вычисляем \(f(x_1)\) и \(f(x_2)\). \(\varepsilon_n = \frac{b - a}{2}, \tau = \frac{\sqrt{5} - 1}{2} \).
    \item [Шаг 2:]
          \begin{itemize}
              \item Если \(\varepsilon_n > \varepsilon\), переходим к шагу 3.
              \item Если \(\varepsilon_n \leq \varepsilon\), переходим к шагу 4.
          \end{itemize}
    \item [Шаг 3:] Сравниваем \(f(x_1)\) и \(f(x_2)\).
          \begin{itemize}
              \item Если \(f(x_1) \leq f(x_2)\), то \(b = x_2, x_2 = x_1, x_1 = b - \tau (b - a)\). Мы запоминаем \(f(x_2)\) для следующего шага, т.к. оно равно \(f(x_1)\) на этом шаге.
              \item Иначе \(a = x_1, x_1 = x_2, f(x_1) = f(x_2)\). Мы запоминаем \(f(x_1)\) для следующего шага, т.к. оно равно \(f(x_2)\) на этом шаге.
          \end{itemize}
    \item [Шаг 4:] \(X^* \approx \overline X = \frac{a_{(n)} + b_{(n)}}{2}\)
\end{itemize}

\subsection{Метод Фибоначчи}

Мы знаем, что \(F_n = \frac{\left( \frac{1 + \sqrt{5}}{2} \right)^n - \left( \frac{1 - \sqrt{5}}{2} \right)^n}{\sqrt{5}} \), а также при \(n \to +\infty\ \) \(F_n \approx \frac{\left( \frac{1 + \sqrt{5}}{2} \right)^n}{\sqrt{5}}\)

Рассмотрим нулевую итерацию:
\[x_1 = a + \frac{F_n}{F_{n + 2}} (b - a) \quad x_2 = a + \frac{F_{n+1}}{F_{n + 2}} (b - a)\]

Рассмотрим \(k\)-тую итерацию:
\[x_1 = a_{(k)} + \frac{F_{n - k + 1}}{F_{n - k + 3}} (b_k - a_k) = a_k + \frac{F_{n - k + 1}}{F_{n + 2}} (b_0 - a_0)\]
\[x_2 = a_{(k)} + \frac{F_{n - k + 2}}{F_{n - k + 3}} (b_k - a_k) = a_k + \frac{F_{n - k + 2}}{F_{n + 2}} (b_0 - a_0)\]

Пусть \(k = n\), тогда:
\[x_1 = a_n + \frac{F_1}{F_{n + 2}} (b_0 - a_0) \quad x_2 = a_n + \frac{F_2}{F_{n + 2}} (b_0 - a_0)\]

Условие на погрешность:
\[\frac{b_n - a_n}{2} = \frac{b_0 - a_0}{F_{n + 2}} < \varepsilon\]
Какое брать \(n?\) Такое, что \(\frac{b_0 - a_0}{\varepsilon} < F_{n + 2}\)

Есть проблема, при большом \(n\) \(\frac{F_n}{F_{n + 2}}\) есть бесконечная десятичная дробь, вследствие чего образуется погрешность.

\subsection{Метод парабол}

\begin{figure}[h]
    \centering
    \includesvg{images/метод_параболы.svg}
    \caption{Функция \(f(x)\) и её приближение параболой.}
\end{figure}

Пусть \(\exists x_1, x_2, x_3\in[a, b]\), такие что \(\begin{cases}
    x_1 < x_2 < x_3 \\
    f(x_1) \geq f(x_2) \leq f(x_3)
\end{cases}\)

Тогда приближающая парабола имеет вид \(q(x) = a_0 + a_1(x - x_1) + a_2(x - x_1)(x - x_2)\). Мы имеем условия на коэффициенты этой параболы: \(\begin{cases}
    q(x_1) = f(x_1) = f_1 \\
    q(x_2) = f(x_2) = f_2 \\
    q(x_3) = f(x_3) = f_3
\end{cases}\)

Коэффициенты можно найти следующим образом:
\[a_1 = f_1 \quad a_2 = \frac{f_2 - f_1}{x_2 - x_1} \quad a_3 = \frac{1}{x_3 - x_2} \left( \frac{f_3 - f_1}{x_3 - x_1} - \frac{f_2 - f_1}{x_2 - x_1} \right) \]

Тогда результат итерации есть \(\overline x = \frac{1}{2} \left( x_1 + x_2 - \frac{a_1}{a_2} \right)\), на следующей лекции будет рассказан переход к следующей итерации.

Точки \(x_1, x_2, x_3\) для новой итерации выбираются следующим образом:
\begin{enumerate}
    \item \begin{enumerate}
              \item Если \(x_1 < \overline x < x_2 < x_3\) и \(f(\overline x) \geq f(x_2)\), то \(x^* \in [\overline x, x_3], x_1 = \overline x\), точки \(x_2\) и \(x_3\) не меняются.
              \item Если \(x_1 < \overline x < x_2 < x_3\) и \(f(\overline x) < f(x_2)\), то \(x^* \in [x_1, x_2], x_3 = x_2, x_2 = \overline x\), точка \(x_1\) не меняется.
          \end{enumerate}
    \item \begin{enumerate}
              \item Если \(x_1 < x_2 < \overline x < x_3\) и \(f(\overline x) \leq f(x_2)\), то \(x^* \in [x_2, x_3], x_1 = x_2, x_2 = \overline x\), точка \(x_3\) не меняется.
              \item Если \(x_1 < x_2 < \overline x < x_3\) и \(f(\overline x) > f(x_2)\), то \(x^* \in [x_1, \overline x], x_3 = \overline x\), точки \(x_1\) и \(x_2\) не меняются.
          \end{enumerate}
\end{enumerate}

\begin{remark}
    Метод парабол имеет квадратичную сходимость.
\end{remark}

\begin{remark}
    Метод парабол требует гладкость функции, что неверно для предыдущих методов.
\end{remark}

\subsection{Комбинированный метод Брента}

Для собственного изучения.

\chapter{24 февраля}

\subsection{Метод равномерного перебора}

\begin{itemize}
    \item [Шаг 1:] Если \(f(x_0) > f(x_0 + \delta)\), то \(k = 1, x_1 = x_0 + \delta, h = \delta\)

          иначе \(x_1 = x_0, h = - \delta\)

    \item [Шаг 2:] \(h = 2h, x_{k+1} = x_k + h\)
    \item [Шаг 3:] Если \(f(x_k) > f(x_{k+1})\), то \(k = k + 1\) и переходим к шагу 2. Иначе прекращаем поиск и искомое лежит в \([x_{k - 1}, x_{k + 1}]\)
\end{itemize}

\section{Методы оптимизации, использующие производную}

В рамках этой главы \(f(x)\) --- дифференцируемая или дважды дифференцируемая выпуклая функция.

Есть три классических метода, использующих производную:
\begin{itemize}
    \item Средней точки
    \item Метод хорд
    \item Метод Ньютона
\end{itemize}

\(f'(x) = 0\) --- необходимое и достаточное условие глобального минимума. Таким образом, условие остановки вычислений --- \(f'(x) \approx 0\), т.е. \(|f'(x)| \leq \varepsilon\)

\subsection{Методы средней точки}

Средняя точка \(\overline x = \frac{a + b}{2}\).

Общая идея алгоритма:
\begin{itemize}
    \item Если \(f'(x) > 0\), то \(\overline x\in\) участку монотонного возрастания \(f(x)\) и \(x^* < \overline x\), т.е. минимум лежит на \([a, \overline x]\)
    \item Если \(f'(x) < 0\), то аналогично можем вывести, что минимум лежит на \([\overline x, b]\)
    \item Если \(f'(x) = 0\), то мы нашли решение.
\end{itemize}

Перепишем это в виде алгоритма:

\begin{itemize}
    \item [Шаг 1:] \(\overline x = \frac{a + b}{2}\), вычислим \(f'(\overline x)\)
    \item [Шаг 2:] Если \(|f'(x)| \leq \varepsilon\), то \(x^* = \overline x\) и завершаем вычисление.
    \item [Шаг 3:] Сравниваем \(f'(x)\) с нулём: \begin{itemize}
              \item Если \(f'(x) > 0\), то \(x^*\in[a, \overline x]\) и \(b = \overline x\)
              \item Иначе \(x^*\in[\overline x, b]\) и \(a = \overline x\)
          \end{itemize}
\end{itemize}

Длина отрезка после \(n\) итераций есть \(\Delta_n = \frac{b - a}{2^n}\)

\subsection{Метод хорд \textit{(метод секущей)}}

Если \(\exists f'(x)\) на \([a, b]\), \(f'(a) \cdot f'(b) < 0\) и \(f'(x)\) непрерывна на \([a, b]\), то \(\exists x\in(a, b) : f'(x) = 0\).

\(F(x) = f'(x)\). Пусть \(\tilde{x}\) --- точка пересечения хорды \(F(x)\) с осью \(Ox\) на \([a, b]\)

\begin{figure}[h]
    \centering
    \includesvg[scale=0.9]{images/хорда.svg}
\end{figure}

Можем тривиально вывести \(\tilde{x}\) из уравнения прямой по двум точками:
\begin{equation}
    \tilde{x} = a - \frac{f'(a)}{f'(a) - f'(b)}(a - b) \label{пересечение хорды}
\end{equation}

\begin{itemize}
    \item [Шаг 1:] Считаем \(\tilde{x}\) по \eqref{пересечение хорды}
    \item [Шаг 2:] Если \(|f'(\tilde{x})| \leq \varepsilon\), то \(x^* = \tilde{x}\) и мы заканчиваем вычисление.

          Иначе шаг 3.
    \item [Шаг 3:] Переходим к новому отрезку:
          \begin{itemize}
              \item Если \(f'(\tilde{x}) > 0\), то \(x^* \in [a, \tilde{x}], b = \tilde{x}, f'(b) = f'(\tilde{x})\), переходим к шагу 1
              \item иначе \(x^* \in [\tilde{x}, b], a = \tilde{x}, f'(a) = f'(\tilde{x})\), переходим к шагу 1
          \end{itemize}
\end{itemize}

\begin{remark}
    Если \(f'(a) \cdot f'(b) \geq 0\), то \(x^* = a\) или \(x^* = b\).
\end{remark}

\subsection{Метод Ньютона \textit{(метод касательной)}}

Если \(f\) выпуклая на \([a, b]\) и дважды непрерывно дифференцируемая, то уравнение \(f'(x) = 0\) решается методом Ньютона.

Пусть \(x_0 \in [a, b]\) --- начальное приближение \(x^*\). \(F(x) = f'(x)\) линеаризуема в окрестности \(x_0\), т.е.
\begin{equation}
    F(x) \approx F(x_0) + F'(x_0)(x - x_0)
\end{equation}

Пусть \(x_1\) --- следующее приближение к \(x^*\). Это будет пересечение касательной с \(Ox\). Найдём эту точку.

\begin{align*}
    F(x_0) + F'(x_0) (x_1 - x_0) & = 0                            \\
    x_1                          & = x_0 - \frac{F(x_0)}{F'(x_0)}
\end{align*}

Таким образом, мы можем получить \(\{x_k\}_{k = 1}^{n}\) --- итерационную последовательность.

\[x_{k+1} = x_k - \frac{f'(x_k)}{f''(x_k)} \]

Условие остановки такое же, как в предыдущих методах: \(|f'(x_k)| \leq \varepsilon\)

\end{document}
