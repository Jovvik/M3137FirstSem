\chapter{20 марта}

\section{Случайные величины}

\begin{example}\itemfix
    \begin{enumerate}
        \item Бросаем кость. \(\xi\) --- число выпавших очков. \(\xi \in \{1, 2, 3, 4, 5, 6\} \)
        \item Достали случайную микросхему из ящика. \(\xi\) --- время работы до отказа.
              \begin{enumerate}
                  \item Пусть время измеряется в часах. Тогда \(\xi \in \{0, 1, 2, 3 \dots \} \)
                  \item Пусть время измеряется точно. Тогда \(\xi \in [0, +\infty)\)
              \end{enumerate}
        \item \(\xi\) --- температура воздуха в текущий момент времени. \(\xi \in ( - 50^\circ, 50^\circ)\)
        \item \(\xi\) --- индикатор события \(A\). Обозначается \(I_A = \begin{cases}
                  0, & A \text{ не наступает} \\
                  1, & A \text{ наступает}    \\
              \end{cases}\)
    \end{enumerate}
\end{example}

\begin{definition}
    Пусть имеется вероятностное пространство \((\Omega, \mathfrak{F}, P)\). Функция \(\xi : \Omega \to \R\) называется \textbf{\(\mathfrak{F}\)-измеримой}, если \(\forall x\in \R  \ \ \{w : \xi(w) < x\} \in \mathfrak{F}\). Иными словами, прообраз \(\xi^{ - 1}( - \infty, x)\in \mathfrak{F}\).
\end{definition}

\begin{definition}
    \textbf{Случайной величиной} \(\xi\), заданной на пространстве \(\Omega, \mathfrak{F}, P\), называется \(\mathfrak{F}\)-измеримая функция \(\xi : \Omega \to \R\), ставящая в соотвествие каждому элементарному исходу некоторое вещественное число.
\end{definition}

\begin{remark}
    Не все функции являются измеримыми.
\end{remark}

\begin{example}
    Бросаем кость. \(\Omega = \{1, 2, 3, 4, 5, 6\}, \mathfrak{F} = \{\emptyset, \Omega, \{1, 3, 5\}, \{2, 4, 6\} \} \). \(\xi(i) = i\)

    Пусть \(x = 4\), \(\{w : \xi(w) < 4\} = \{1, 2, 3\} \notin \mathfrak{F}\). \(\xi\) не измеримо.
\end{example}

\begin{exercise}
    Описать класс измеримых функций для тривиальной \(\sigma\)-алгебры \(\{\emptyset, \Omega\}\)
\end{exercise}

Пусть \(\xi : \Omega \to \R\) измерима. Тогда \(P(\xi < x) = P(\underbrace{\{w : \xi(w) < x\}}_{A_x})\), т.к. \(A_x \in \mathfrak{F}\), а также:
\begin{itemize}
    \item \(\overline{A_x} = \{w : \xi(w) \geq x\} \in \mathfrak{F}\)
    \item При \(x > y\) \(A_x \setminus B_y = \{w : y \leq \xi(w) < x\} \in \mathfrak{F}\).
    \item \(B_x = \bigcap_{t = 1}^{\infty} A_{x - \frac{1}{t}} = \{w : \xi(w) \leq x\} \)
    \item \(B_x \setminus A_x = \{w : \xi(w) = x\} \in \mathfrak{F}\)
\end{itemize}

Отсюда видим, что по теореме Каратеодори вероятностную меру можно продолжить до любого борелевского множества \(B \in \mathfrak{B}\), где \(\mathfrak{B}\) --- борелевская \(\sigma\)-алгебра.

\[P(B \in \mathfrak{B}) = P(\{w : \xi(w) \in B\})\]

Итак, пусть случайная величина \(\xi\) задана на вероятностном пространстве \((\Omega, \mathfrak{F}, P)\). Тогда:
\begin{enumerate}
    \item \((\Omega, \mathfrak{F}, P) \xrightarrow{\xi} (\R, \mathfrak{B}, P)\)
    \item В свою очередь совокупность прообразов \(\xi^{ - 1}(B) \ \ \forall B\in \mathfrak{B}\) является \(\sigma\)-алгеброй \(\mathfrak{F}_\xi \subset \mathfrak{F}\). Такая \(\sigma\)-алгебра называется \textbf{\(\sigma\)-алгеброй, порожденной случайной величиной \(\xi\)}.
\end{enumerate}

\begin{exercise}
    Найти \(\sigma\)-алгебру, порожденную индикатором \(I_A = \begin{cases} 0, & w\notin A \\ 1, & w\in A \end{cases} \)
\end{exercise}

\begin{definition}
    Функция \(P(B), B \in \mathfrak{B}\) называется \textbf{распределением вероятностей} случайной величины \(\xi(w)\), т.е. распределение с.в. это соотвествие между множествами на вещественной прямой и вероятностями случайной величины попасть в это множество.
\end{definition}

\subsection{Основные типы распределений}

\begin{enumerate}
    \item Дискретное
    \item Абсолютно непрерывное
    \item Смешанное
    \item Сингулярное --- непрерывное, но не абсолютно непрерывное
\end{enumerate}

Мы будем рассматривать только первые два. Соответствующие величины мы также будем называть дискретными или непрерывными.

\subsection{Дискретные случайные величины}

\begin{definition}
    Случайная величина \(\xi\) имеет \textbf{дискретное распределение}, если она принимает не более чем счётное число значений, то есть существует конечный или счётный набор чисел \(x_1 \dots x_n \dots \), такой что \(p_i = P(\xi = x_i) > 0\) и \(\sum p_i = 1\)
\end{definition}
Дискретная случайная величина задаётся законом распределения \textit{(рядом, таблицей)}.


\begin{example}
    Кость.

    \begin{tabular}{C|C|C|C|C|C|C}
        \xi & 1           & 2           & 3           & 4           & 5           & 6           \\ \hline
        P   & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6}
    \end{tabular}
\end{example}

\subsection{Основные числовые характеристики дискретной случайной величины}

\subsubsection{Математическое ожидание \textit{(среднее значение)}}

\begin{definition}
    \textbf{Математическим ожиданием} \(\mathbb{E}\xi\) называется число \(\mathbb{E}\xi = \sum_i x_ip_i\) при условии, что данный ряд сходится абсолютно. В противном случае говорят, что матожидания не существует.
\end{definition}

\begin{remark}
    Смысл: значения случайной величины группируются вокруг матожидания.
\end{remark}

\subsubsection{Дисперсия}

\begin{definition}
    \textbf{Дисперсией} \(\mathbb{D}\xi\) случайной величины \(\xi\) называется среднее квадратов отклонений этой величины от математического ожидания: \(\mathbb{D}\xi = \mathbb{E}(\xi - \mathbb{E}x)^2\) или \(\mathbb{D}\xi = \sum_i (x_i - \mathbb{E}\xi)^2 - p_i\) при условии, что данное значение существует \textit{(конечно)}.
\end{definition}

\begin{remark}
    Вычислять дисперсию удобнее по формуле \(\mathbb{D}\xi = \mathbb{E}\xi^2 - (\mathbb{E}\xi)^2 = \sum_i x_i^2 p_i - (\mathbb{E}\xi)^2\)
\end{remark}

\begin{remark}
    Смысл: квадрат среднего разброса рассеяния случайной величины около её математического ожидания.
\end{remark}

\subsubsection{Среднеквадратическое отклонение}

\begin{definition}
    \textbf{Среднеквадратическим отклонением} \(\sigma_\xi\) случайной величины \(\xi\) называется число \(\sigma = \sqrt{\mathbb{D}\xi}\)
\end{definition}

\begin{remark}
    Смысл: характеризует средний разброс случайной величины около её математического ожидания.
\end{remark}

\begin{example}
    Кость.

    \begin{tabular}{C|C|C|C|C|C|C}
        \xi & 1           & 2           & 3           & 4           & 5           & 6           \\ \hline
        P   & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6}
    \end{tabular}

    \[\mathbb{E}\xi = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6} = 3.5\]
    \[\mathbb{D}\xi = 1^2 \cdot \frac{1}{6} + 2^2 \cdot \frac{1}{6} + 3^2 \cdot \frac{1}{6} + 4^2 \cdot \frac{1}{6} + 5^2 \cdot \frac{1}{6} + 6^2 \cdot \frac{1}{6} - 3.5^2 \approx 2.32\]
    \[\sigma \approx \sqrt{2.32} \approx 1.71\]
\end{example}

\subsection{Свойства математического ожидания и дисперсии}

\begin{definition}
    Случайная величина \(\xi\) имеет вырожденное распределение, если \(\xi(w) = C \ \ \forall w \in \Omega\).
\end{definition}

\begin{prop}\itemfix
    \begin{enumerate}
        \item \(\mathbb{E}C = C, \mathbb{D}C = 0\)
              \begin{proof}
                  \[\mathbb{E}C = C \cdot 1 = C\]
                  \[\mathbb{D}C = \mathbb{E}(\underbrace{C - \mathbb{E}C}_0) = 0\]
              \end{proof}

        \item \(\mathbb{E}(\xi + C) = \mathbb{E}\xi + C, \mathbb{D}(\xi + C) = \mathbb{D}\xi\)
              \begin{proof}
                  \[\mathbb{E}(\xi + C) = \sum_i (x_i + C)p_i = \sum_i x_i p_i + C \underbrace{\sum_i p_i}_1 = \mathbb{E}\xi + C\]
                  \[\mathbb{D}(\xi + C) =  \mathbb{E}(\xi + C - \mathbb{E}(\xi + C))^2 = \mathbb{E}(\xi + C - \mathbb{E}\xi - C)^2 = \mathbb{E}(\xi - \mathbb{E}\xi)^2 = \mathbb{D}\xi\]
              \end{proof}

        \item Растяжение: \(\mathbb{E}(C\xi) = C \mathbb{E}\xi, \mathbb{D}(C\xi) = C^2 \mathbb{D}\xi\)
              \begin{proof}
                  \[\mathbb{E}(C\xi) = \sum_i C x_i p_i = C \sum_i x_i p_i = C \mathbb{E}\xi\]
                  \[\mathbb{D}(C\xi) = \mathbb{E}(C\xi - \mathbb{E}C\xi)^2 = C^2 \mathbb{E}(\xi - \mathbb{E}\xi)^2 = C^2 \mathbb{D}\xi\]
              \end{proof}

        \item \(\mathbb{E}(\xi + \eta) = \mathbb{E}\xi + \mathbb{E}\eta\)
              \begin{proof}
                  Пусть \(x_i, y_j\) --- соответствующие значения случайных величин \(\xi\) и \(\eta\).

                  \begin{align*}
                      \mathbb{E}(\xi + \eta) & = \sum_{i, j} (x_i + y_j)P(\xi = x_i, \eta = y_j)                                         \\
                                             & = \sum_i x_i \sum_j P(\xi = x_i, \eta = y_j) + \sum_j y_j \sum_i P(\xi = x_j, \eta = y_i) \\
                                             & = \sum_i x_i P(\xi = x_i) + \sum_j y_j P(\eta = y_j)                                      \\
                                             & = \mathbb{E} \xi + \mathbb{E} \eta
                  \end{align*}

              \end{proof}

              \begin{definition}
                  Дискретные случайные величины \(\xi\) и \(\eta\) \textbf{независимы}, если \(P(\xi = x_i, \eta = y_j) = P(\xi = x_i)P(\eta = y_j) \ \ \forall i,j\), т.е. случайные величины принимают свои значения независимо друг от друга.
              \end{definition}

        \item Если \(\xi\) и \(\eta\) независимы, то \(\mathbb{E}(\xi\cdot\eta) = \mathbb{E}\xi\cdot\mathbb{E}\eta\)
              \begin{proof}
                  \begin{align*}
                      \mathbb{E}(\xi\cdot\eta) & = \sum_{i, j} x_i y_j P(\xi = x_i, \eta = y_j)     \\
                                               & = \sum_i x_i \sum_j y_j P(\xi = x_i, \eta = y_j)   \\
                                               & = \sum_i x_i \sum_j y_j P(\xi = x_i) P(\eta = y_j) \\
                                               & = \sum_i x_i P(\xi = x_i) \sum_j y_j P(\eta = y_j) \\
                                               & = \sum_i x_i P(\xi = x_i) \mathbb{E}\eta           \\
                                               & = \mathbb{E}\xi \mathbb{E}\eta                     \\
                  \end{align*}
              \end{proof}

              В обратную сторону это утверждение не верно.

        \item \(\mathbb{D}\xi = \mathbb{E}\xi^2 - (\mathbb{E}\xi)^2\)
              \begin{proof}
                  \begin{align*}
                      \mathbb{D}\xi & = \mathbb{E}(\xi - \mathbb{E}\xi^2)                                             \\
                                    & = \mathbb{E}(\xi^2 - 2\xi\mathbb{E}\xi + (\mathbb{E}\xi)^2)                     \\
                                    & = \mathbb{E}\xi^2 - 2 \mathbb{E}\xi \mathbb{E}\xi + \mathbb{E}(\mathbb{E}\xi^2) \\
                                    & = \mathbb{E}\xi^2 - 2(\mathbb{E}\xi)^2 + (\mathbb{E}\xi)^2                      \\
                                    & = \mathbb{E}\xi^2 - (\mathbb{E}\xi)^2
                  \end{align*}
              \end{proof}

        \item \(\mathbb{D}(\xi + \eta) = \mathbb{D}\xi + \mathbb{D}\eta + 2 \cdot \cov(\xi, \eta)\), где \(\cov(\xi, \eta) = \mathbb{E}(\xi \cdot \eta) - \mathbb{E}\xi \cdot \mathbb{E} \eta\) --- ковариация.

              \begin{proof}
                  \begin{align*}
                      \mathbb{D}(\xi + \eta) & = \mathbb{E}(\xi + \eta)^2 - (\mathbb{E}(\xi + \eta))^2                                                                                 \\
                                             & = \mathbb{E}(\xi^2 + 2\xi\eta + \eta^2) - (\mathbb{E}\xi + \mathbb{E}\eta)^2                                                            \\
                                             & = \mathbb{E} \xi^2 + 2 \mathbb{E} \xi\eta + \mathbb{E} \eta^2 - (\mathbb{E} \xi)^2 - (\mathbb{E} \eta)^2 - 2\mathbb{E}\xi\mathbb{E}\eta \\
                                             & = \mathbb{D}\xi + \mathbb{D}\eta + 2 (\mathbb{E} \xi\eta - \mathbb{E}\xi\mathbb{E}\eta)                                                 \\
                  \end{align*}
              \end{proof}

        \item Если случайные величины \(\xi\) и \(\eta\) независимы, то \(\mathbb{D}(\xi + \eta) = \mathbb{D} \xi + \mathbb{D} \eta\)

              \begin{proof}
                  \(\cov(\xi, \eta) = 0\)
              \end{proof}

        \item Среднеквадратическое отклонение --- минимум отклонения случайной величины от точек вещественной прямой: \(\mathbb{D} = \min_a (\xi - a)^2\)

              \begin{proof}
                  \begin{align*}
                      \mathbb{E}(\xi - a)^2 & = \mathbb{E}((\xi - \mathbb{E}\xi) + (\mathbb{E}\xi - a))^2                                                               \\
                                            & = \mathbb{E}(\xi - \mathbb{E}\xi)^2 + 2\mathbb{E}(\xi - \mathbb{E}\xi) \cdot (\mathbb{E} \xi - a) + (\mathbb{E}\xi - a)^2 \\
                                            & = \mathbb{D}\xi + (\mathbb{E}\xi - a)^2 \leq \mathbb{D}\xi
                  \end{align*}
              \end{proof}
    \end{enumerate}
\end{prop}

\subsection{Другие числовые характеристики}

\begin{enumerate}
    \item \(M_k = \mathbb{E} y^k\) --- момент \(k\)-го порядка. В частности, при \(k = 1\) это матожидание.
    \item \(\mathbb{E}|y|^k\) --- абсолютный момент \(k\)-го порядка
    \item \(\mu_k = \mathbb{E}(\xi - \mathbb{E}\xi)^k\) --- центральный момент \(k\)-го порядка. В частности, при \(k = 1\) это дисперсия.
    \item \(\mathbb{E}(\xi - \mathbb{E}\xi)^k\) --- абсолютный центральный момент \(k\)-го порядка.
\end{enumerate}

\begin{remark}
    Центральные моменты можно выразить через моменты.
\end{remark}

\begin{remark}
    Обычно не рассматривают моменты выше, чем \(4\) порядка.
\end{remark}

\subsubsection{Мода}

\begin{definition}
    \textbf{Модой} \(M_o\) называется такое значение случайной величины, где вероятность события является наибольшей: \(P(\xi - M_o) = \max_i p_i\)
\end{definition}

\subsubsection{Медиана}

\begin{definition}
    \textbf{Медианой} \(M_e\) называется значение случайной величины такое, что вероятность того, что \(P(\xi < M_e) = P(\xi > M_e)\). Обычно используется для обычной случайной величины, т.к. для дискретной величины медиана может не существовать.
\end{definition}