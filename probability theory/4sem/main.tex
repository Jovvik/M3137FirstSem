\documentclass[12pt, a4paper, oneside]{book}

\usepackage{catchfilebetweentags}
\ExecuteMetaData[../../preamble.sty]{preamble}

\addto\captionsrussian{\renewcommand{\chaptername}{Лекция}}

\let\MakeUppercase\relax

\lfoot{}
\cfoot{}
\rfoot{}
\lhead{\leftmark}

\usepackage{tocloft}
\advance\cftsecnumwidth -1em\relax
\advance\cftsubsecindent -1em\relax
\advance\cftsubsecnumwidth -1em\relax

\usepackage{titletoc}
\titlecontents*{chapter}% <section-type>
  [0pt]% <left>
  {}% <above-code>
  {\bfseries\chaptername\ \thecontentslabel\quad}% <numbered-entry-format>
  {}% <numberless-entry-format>
  {\bfseries\hfill\contentspage}% <filler-page-format>

\let\endtitlepage\relax

\usepackage{remreset}
\makeatletter
  \@removefromreset{section}{chapter}
\makeatother

\patchcmd{\chapter}{\thispagestyle{plain}}{\thispagestyle{fancy}}{}{}

\renewcommand{\thesection}{\arabic{section}}

\begin{document}

\title{Теория вероятности}
\author{Михайлов Максим}

\maketitle

\tableofcontents

\chapter{13 февраля}

\section{События}

\subsection{Статистическое определение вероятности}

\begin{definition}
    Пусть проводится \(n\) реальных экспериментов, событие \(A\) произошло в \(n_A\) экспериментах. Отношение \(\cfrac{n_A}{n}\) называется \textbf{частотой события} \(A\). Эксперименты показывают, что при увеличении числа \(n\) эта частота ``стабилизируется'' около некоторого числа, под которым понимаем \textbf{статистическую вероятность}.
    \[P(A)\approx \frac{n_A}{n}\]
\end{definition}

Очевидно это определение не формально, поэтому мы им пользоваться не будем.

\subsection{Пространство элементарных исходов. Случайные события.}

\begin{definition}\itemfix
    \begin{itemize}
        \item \textbf{Пространством элементарных исходов} \(\Omega\) называется множество, содержащее все возможные результаты данного эксперимента, из которых при испытании происходит ровно один.
        \item Элементы данного множества называются \textbf{элементарными исходами} и обозначаются \(w\in \Omega\).
        \item \textbf{Случайными событиями} называются подмножества \(A\subset \Omega\).
        \item Событие \(A\) \textbf{наступило}, если в ходе эксперимента произошёл один из элементарных исходов, входящих в \(A\).
        \item Такие исходы называются \textbf{благоприятными} к \(A\).
    \end{itemize}
\end{definition}

\begin{example}\itemfix
    \begin{enumerate}
        \item Бросают монетку. \(\Omega = \{\text{Г}, \text{Р}\} \) \textit{(герб, решка)}.
        \item Бросают кубик. \(\Omega = \{1,2,3,4,5,6\} \). \(A\) --- выпало четное число очков. Тогда \(A = \{2,4,6\} \).
        \item Монета бросается дважды:
              \begin{enumerate}
                  \item Учитываем порядок: \(\Omega = \{\text{ГГ, РР, ГР, РГ}\} \)
                  \item Не учитываем порядок: \(\Omega = \{\text{ГГ, РР, ГР}\} \)
              \end{enumerate}
        \item Бросается дважды кубик, порядок учитывается. \(A\) --- разность очков делится на 3, т.е. \(A = \{(1,4), (4,1), (3,3), (5,2), (2,5), (3, 6), (6, 3), (1, 1), (2, 2), (4, 4), (5, 5), (6, 6)\} \)
        \item Монета бросается до выпадения герба. \(\Omega = \{\text{Г, РГ, РРГ, \dots}\} \) --- счётное число исходов.
        \item Монета бросается на плоскость. \(\Omega = \{(x, y) \ | \ x, y\in\R\} \) --- несчётное число исходов.
    \end{enumerate}
\end{example}

\subsection{Операции над событиями}

\(\Omega\) --- универсальное \textit{(достоверное)} событие, т.к. содержит все элементарные исходы.

\(\emptyset\) --- невозможное событие.

\begin{definition}
    \(A + B\) это \(A\cup B\)

    \begin{figure}[h]
        \centering
        \includesvg[scale=0.5]{images/intersection.svg}
    \end{figure}
\end{definition}

\begin{definition}
    \(A\cdot B\) это \(A\cap B\)

    \begin{figure}[h]
        \centering
        \includesvg[scale=0.5]{images/union.svg}
    \end{figure}
\end{definition}

\begin{definition}
    \textbf{Противоположным} к \(A\) называется событие \(\overline A\), соответствующее тому, что \(A\) не произошло, т.е. \(\Omega\setminus A\)
\end{definition}

\begin{definition}
    Дополнение \(A\setminus B\) это \(A\cdot \overline B\)
\end{definition}

\begin{definition}
    События \(A\) и \(B\) называются \textbf{несовместными}, если \(A\cdot B = \emptyset\)
\end{definition}

\begin{definition}
    Событие \(A\) влечет событие \(B\), если \(A\subset B\).
\end{definition}

\section{Вероятность}

\begin{definition}
    \(0 \leq P(A) \leq 1\) --- вероятность наступления события \(A\).
\end{definition}

\subsection{Классическое определение вероятности}

Пусть \(\Omega\) содержит конечное число исходов, причем их можно считать равновозможными. Тогда применимо классическое определение вероятности.

\(P(A) = \cfrac{|A|}{|\Omega|} = \cfrac{m}{n}\), где \(n\) --- число всех возможных элементарных исходов, \(m\) --- число элементарных исходов, благоприятных \(A\).

В частности, если \(|\Omega|= n\), а \(A\) --- элементарный исход, то \(P(A) = \frac{1}{n}\).

\begin{prop}\itemfix
    \begin{enumerate}
        \item \(0 \leq P(A) \leq 1\)
        \item \(P(\emptyset) = 0\)
        \item \(P(\Omega) = 1\)
        \item \? % TODO #65
    \end{enumerate}
\end{prop}

Если \(A\) и \(B\) несовместны, то \(P(A + B) = P(A) + P(B)\)

\begin{proof}
    \(|A| : = m_1, |B| : = m_2, |A\cup B|= m_1 + m_2\)

    \[P(A + B) = \frac{m_1 + m_2}{n} = \frac{m_1}{n} + \frac{m_2}{n} = P(A) + P(B)\]
\end{proof}

\begin{example}
    Найти вероятность, что при бросании кости выпадет чётное число очков.

    \[n = 6, m = 3, \frac{m}{n} = \frac{1}{2}\]
\end{example}

\begin{example}
    В ящике лежат 3 белых и 2 чёрных шара. Вынули 3 шара. Найти вероятность того, что из них две белых и один чёрный.

    \[n = \binom{5}{3} = 10\]
    \[m = \binom{3}{2} \binom{2}{1} = 12\]
    \[P(A) = \frac{6}{10}\]
\end{example}

Однако, это определение редко применимо.

\subsection{Геометрическое определение вероятности}

\begin{definition}\itemfix
    \begin{itemize}
        \item \(\Omega \subset \R^n\) --- замкнутая ограниченная область.
        \item \(\mu\) --- конечная мера множества \(\Omega\), например мера Лебега
    \end{itemize}

    Пусть выбирают точку наугад, т.е. вероятность попадания точки в область \(A\) зависит от меры \(A\), но не от её положения.

    Тогда
    \(P(A) = \cfrac{\mu(A)}{\mu(\Omega)}\)
\end{definition}

\begin{remark}
    По этому определению мера точки равна \(0\) и вероятность попадания в конкретную точку тоже равна \(0\).
\end{remark}

\begin{example}
    Монета диаметром 6 сантиметров бросается на пол, вымощенный квадратной плиткой со стороной 20 сантиметров. Найти вероятность того, что монета целиком окажется на одной плитке.

    Без ущерба для общности можно рассматривать, что монета бросается на одну плитку и положение монеты определяется положением её центра.

    Чтобы монета лежала полностью на одной плитке, необходимо, чтобы её центр лежал на расстоянии \( \geq 3\) сантиметра от каждой стороны:

    \begin{figure}[h]
        \centering
        \includesvg[scale=0.8]{images/задача-1.svg}
    \end{figure}

    \[S(\Omega) = 20^2 = 400\]
    \[S(A) = 14^2 = 196\]
    \[P(A) = \frac{196}{400} = 0.49\]
\end{example}

\begin{example}
    \? % TODO #64

    \[A : X \leq l \sin \varphi\]
    \[S(\Omega) = \pi l\]
    \[S(A) = \int_0^\pi l \sin \varphi d\varphi = - l \cos \varphi \Big|_0^\pi = - l(\cos \pi - \cos 0) = 2l\]
    \[P(A) = \frac{S(A)}{S(\Omega)} = \frac{2}{\pi}\]
\end{example}

Это определение кажется хорошим --- оно согласовано с классическим. Но и это определение редко применимо на практике, т.к. обычно вероятность зависит от положения в пространстве или множество исходов несчётно.

\chapter{20 февраля}

\subsection{Аксиоматическое определение вероятности}

Пусть \(\Omega\) --- пространство элементарных исходов.

\begin{definition}
    Систему \(\mathcal{F}\) подмножеств \(\Omega\) называют \(\sigma\)-алгеброй событий, если:
    \begin{enumerate}
        \item \(\Omega\in\mathcal{F}\)
        \item \(A\in \mathcal{F} \Rightarrow \overline A \in \mathcal{F}\)
        \item \(A_1 \dots A_n \dots \in \mathcal{F} \Rightarrow \bigcup\limits_{i = 1}^{+\infty} A_i \in \mathcal{F}\)
    \end{enumerate}
\end{definition}

\begin{remark}
    Из 2 и 3 следует 1.
\end{remark}

\begin{prop}\itemfix
    \begin{enumerate}
        \item \(\emptyset \in \mathcal{F}\), т.к. \(\overline \Omega = \emptyset\)
        \item \(A_1 \dots \in \mathcal{F} \Rightarrow \bigcup A_i \in \mathcal{F}\)

              \begin{proof}
                  \(A_1 \dots \in \mathcal{F} \Rightarrow \overline A_1 \dots \in \mathcal{F} \Rightarrow \bigcup \overline A_i \in \mathcal{F} \Rightarrow \overline{\bigcup \overline A_i} = \bigcap A_i \in \mathcal{F}\)
              \end{proof}

        \item \(A, B \in F \Rightarrow A\setminus B \in \mathcal{F}\)
    \end{enumerate}
\end{prop}

\? % TODO

\begin{definition}
    Пусть \(\Omega\) --- множество элементарных исходов, \(\mathcal{F}\) --- \(\sigma\)-алгебра над ним.

    \textbf{Вероятностью} на \((\Omega, \mathcal{F})\) называется функция \(P(A) : \mathcal{F} \to \R\) со свойствами:
    \begin{enumerate}
        \item \(P(A) \geq 0\) --- свойство неотрицательности
        \item Если события \(A_1 \dots A_n \dots \) --- равновероятные, т.е. \(A_i \cap A_j = \emptyset\), то \(P(\bigcap A) = \sum P(A_i)\) --- свойство счётной аддитивности
        \item \(P(\Omega) = 1\) --- свойство нормированности
    \end{enumerate}
\end{definition}

\begin{remark}
    Вероятность есть нормированная мера.
\end{remark}

\begin{definition}
    Тройка \((\Omega, \mathcal{F}, P)\) называется вероятностным пространством.
\end{definition}

\begin{prop}\itemfix
    \begin{enumerate}
        \item \(P(\emptyset) = 0\)

              \begin{proof}
                  \(\underbrace{P(\emptyset + \Omega)}_{1} = P(\emptyset) + \underbrace{P(\Omega)}_1 \Rightarrow P(\emptyset) = 0\)
              \end{proof}

        \item Формула обратной вероятности: \(P(A) = 1 - P(\overline A)\)

              \begin{proof}
                  \(A\) и \(\overline A\) --- несовместны, \(A + \overline A = \Omega\).

                  \(P(A + \overline A) = P(A) + P(\overline A) = 1 \Rightarrow P(A) = 1 - P(\overline A)\)
              \end{proof}

        \item \(0 \leq P(A) \leq 1\)

              \begin{proof}
                  \begin{enumerate}
                      \item \(P(A) \geq 0\)
                      \item \(P(A) = 1 - P(\overline A) \leq 1\)
                  \end{enumerate}
              \end{proof}
    \end{enumerate}
\end{prop}

\subsection{Аксиома непрерывности}

Пусть имеется убывающая цепочка событий \(A_1 \supset A_2 \supset \dots \) и \(\bigcap A_i = \emptyset\). Тогда \(P(A_n) \xrightarrow{n \to +\infty} 0\)

\? % TODO
% соответствующая вероятность также должна изменяться непрерывно.

\begin{theorem}
    Эта аксиома следует из второй аксиомы.
\end{theorem}
\begin{proof}
    \(A_n = \sum_{i = n}^{+\infty} A_i \overline A_{i+1} \cup \bigcap_{i = n}^{+\infty} A_i\)

    \? % TODO

    Т.к. по условию \(P(\bigcap_{i = 1}^{+\infty} A_i) = \emptyset\) и \(\bigcap_{i = n}^{+\infty} A_i = \bigcap_{i = 1}^{+\infty} A_i\), то \(P(\bigcap_{i = n}^{+\infty} A_i) = 0\).

    Таким образом, \(P(A_n) = \sum_{i = n}^{+\infty} P(A_i \overline A_{i + 1})\) --- остаточный член сходящейся последовательности \( \Rightarrow P(A_n) \to 0\)
\end{proof}

\begin{remark}
    Аксиома счётной аддитивности следует из аксиомы непрерывности и свойства конечной аддитивности.
\end{remark}

\subsection{Формула сложения}

Если \(A\) и \(B\) несовместны, то \(P(A + B) = P(A) + P(B)\)

\begin{theorem}
    \(P(A + B) = P(A) + P(B) - P(A B)\)
\end{theorem}
\begin{proof}
    \[A + B = A\overline B + AB + \overline A B\]
    \begin{align*}
        P(A + B) & = P(A\overline B) + P(AB) + P(\overline A B)                     \\
                 & = (P(A\overline B) + P(AB)) + (P(\overline A B) + P(AB)) - P(AB) \\
                 & = P(A) + P(B) - P(AB)
    \end{align*}
\end{proof}

Аналогично можно доказать формулу включения-исключения:
\[P\left(\sum A_i\right) = \sum P(A_i) - \sum_{i < j} P(A_i A_j) + \sum P(A_i A_j A_k) + \dots + ( - 1)^{n - 1} P(A_1 A_2 \dots A_n)\]

\begin{example}
    Опущен.
\end{example}

\section{Независимые события}

\begin{definition}
    События \(A\) и \(B\) называются \textbf{независимыми}, если \(P(AB) = P(A)P(B)\)
\end{definition}

\begin{proof}
    Если \(A\) и \(B\) независимы, то \(A\) и \(\overline{B}\) --- независимы.
\end{proof}
\begin{proof}
    \[P(A) = P(A(B + \overline B)) = P(AB + A\overline B) = P(AB) + P(A\overline B)\]
    \[P(A \overline B) = P(A) - P(AB) = P(A) - P(A)P(B) = P(A)(1 - P(B)) = P(AB)\]
    Таким образом, \(A\) и \(\overline{B}\) --- независимы.
\end{proof}

\begin{definition}
    События \(A_1 \dots A_n\) называются \textbf{независимыми в совокупности}, если для любого набора \(1 \leq i_1 \dots i_n \leq n\) \(P(A_{i_1}, A_{i_2}, \dots A_{i_n}) = P(A_{i_1})P(A_{i_2}) \dots P(A_{i_n})\)
\end{definition}

\begin{example}[Бернштейн]
    Три грани правильного тетраедра выкрашены в красный, синий, зеленый цвета, а четвертая грань --- во все эти три цвета.

    Бросаем тетраедр и смотрим на грань, на которую он упал. События:
    \begin{itemize}
        \item \(A\) --- красный цвет
        \item \(B\) --- синий цвет
        \item \(C\) --- зеленый цвет
    \end{itemize}

    \[P(A) = P(B) = P(C) = \frac{1}{2}\]
    \[P(AB) = P(AC) = P(BC) = \frac{1}{4}\]
    Таким образом, все события попарно независимы.
    \[P(ABС) = \frac{1}{8}\]
\end{example}

\begin{remark}
    Если в условии есть ``хотя бы'', т.е. требуется найти вероятность суммы совместных независимых событий, то применима формула обратной вероятности.
\end{remark}

\begin{example}
    Найти вероятность того, что при четырёх бросаниях кости хотя бы один раз выпадет шестерка.

    \(A_i\) --- при \(i\)-том броске хотя бы один раз выпала шестерка.

    \[P(\overline A_1) = P(\overline A_2) = P(\overline A_3) = P(\overline 4) = \frac{5}{6}\]

    \[\overline A = \overline A_1 \dots \overline A_4\]
    \[P(\overline A) = \left( \frac{5}{6} \right)^4\]
    \[P(A) = 1 - \left( \frac{5}{6} \right)^4\]
\end{example}

\begin{example}
    Два стрелка стреляют по мишени. Вероятность попадания первого стрелка \(0.6\), второго --- \(0.8\). Найти вероятность того, что попадет ровно один стрелок.

    \(A_1\) --- первый стрелок попал, \(A_2\) --- второй стрелок попал, \(A\) --- ровно один попал.

    \[P(A_1) = 0.8, P(\overline A_1) = 0.2, P(A_2) = 0.6, P(\overline A_2) = 0.4\]

    \[A = A_1 \overline A_2 + \overline A_1 A_2\]
    \[P(A) = P(A_1) P(\overline A_2) + P(\overline A_1) P(A_2) = 0.8 \cdot 0.4 + 0.6 \cdot 0.2 = 0.44\]
\end{example}

\chapter{27 февраля}

\section{Условная вероятность}

\begin{obozn}
    \(P(A|B)\) --- вероятность наступления события \(A\), вычисленная в предположении, что событие \(B\) уже произошло.
\end{obozn}

\begin{example}
    Кубик подбрасывается один раз. Известно, что выпало больше \(3\) очков. Какова вероятность, что выпало чётное число очков?

    Пусть \(A\) --- чётное число очков, \(B\) --- больше \(3\) очков.

    \[n = 3 \quad (4, 5, 6) \quad m = 2 \quad (4, 6)\]
    \[P(A | B) = \frac{m}{n} = \frac{2}{3} = \frac{\frac{2}{6}}{\frac{3}{6}} = \frac{P(A \cdot B)}{P(B)}  \]
\end{example}

\begin{definition}
    \textbf{Условной вероятностью} события \(A\) при условии, что имело место событие \(B\), называется величина \(P(A|B) = \frac{P(AB)}{P(B)}\)
\end{definition}

\begin{theorem}
    \(P(A_1 \dots A_n) = P(A_1)\cdot P(A_2 | A_1)\cdot P(A_3| A_2A_1) \dots P(A_n | A_{n - 1}\dots A_1)\)
\end{theorem}
\begin{proof}
    По индукии.
    \begin{itemize}
        \item [\textbf{База}] \(n = 2\) --- по определению полной вероятности.
        \item [\textbf{Переход}] \[P(A_1 \dots A_n) = P(A_1\dots A_{n - 1}) P(A_n | A_1 \dots A_{n - 1}) = P(A_1)\cdot P(A_2 | A_1) \dots P(A_n | A_{n - 1}\dots A_1)\]
    \end{itemize}
\end{proof}

\begin{definition}
    События \(A\) и \(B\) независимы, если \(P(A|B) = P(A)\), что равносильно \(P(AB) = P(A)P(B)\) --- прошлому определению.
\end{definition}
\begin{proof}
    \[P(A|B) = \frac{P(AB)}{P(B)} = P(A) \Leftrightarrow P(AB) = P(A)P(B)\]
\end{proof}

\subsection{Полная группа событий}

\begin{definition}
    События \(H_1\dots H_n\dots \) образуют \textbf{полную группу событий}, если они попарно несовместны и содержат все элементарные исходы.
\end{definition}

\begin{theorem}
    Пусть \(H_1 \dots H_n\) --- полная группа событий. Тогда \(P(A) = \sum_{k = 1}^{+\infty} P(H_i)P(A | H_i)\)
\end{theorem}
\begin{proof}
    \begin{align*}
        P(A) & = P(\Omega A)                                                              \\
             & = P((H_1 + \dots H_n + \dots ) A)                                          \\
             & = P\left(\sum_{k = 1}^{+\infty} H_k A\right)                               \\
             & \symrefeq{по счетной аддитивности} \sum_{k = 1}^{+\infty} P(H_i)P(A | H_i) \\
    \end{align*}

    \ref{по счетной аддитивности}: По лемме о счётной аддитивности и т.к. \(H_iA\) и \(H_jA\) несовместны.
\end{proof}

\subsection{Формула Байеса}

Эта формула также называется формулой проверки гипотезы.

\begin{theorem}
    Пусть \(H_1 \dots H_n\) --- полная группа событий и известно, что \(A\) произошло. Тогда \[P(H_i | A) = \frac{P(H_i)P(A | H_i)}{\sum_{k = 1}^{+\infty} P(H_k)P(A|H_k)} \]
\end{theorem}
\begin{proof}
    \[P(H_i | A) = \frac{P(H_i A)}{P(A)} = \frac{P(H_i)P(A | H_i)}{\sum_{k = 1}^{+\infty} P(H_k)P(A|H_k)}\]
\end{proof}

\chapter{6 марта}

\section{Последовательность независимых испытаний}

\begin{definition}
    Схемой Бернулли называется серия одинаковых независимых испытаний, каждое из которых имеет лишь два исхода --- интересующее нас событие произошло \textit{(успех)} или не произошло \textit{(неудача)}.
\end{definition}

\begin{obozn}\itemfix
    \begin{itemize}
        \item \(n\) --- число испытаний
        \item \(p\) --- вероятность события \(A\) при одном испытании
        \item \(q = 1 - p\)
        \item \(v_n\) --- число успехов при \(n\) испытаниях
        \item \(P_n(k) = P(v_n = k)\)
    \end{itemize}
\end{obozn}

\subsection{Формула Бернулли}

\begin{theorem}
    Вероятность того, что при \(n\) испытаниях произойдёт ровно \(k\) успехов равна:
    \[P_n(k) = \binom{n}{k} p^k q^{n - k}\]
\end{theorem}
\begin{proof}
    Рассмотрим один из исходов, благоприятных событию \(A\): \(A_1 = \underbrace{\text{У} \dots \text{У}}_{k} \underbrace{\text{Н} \dots \text{Н}}_{n-k}\). Т.к. рассматриваемые события независимы, верна следующая формула:

    \[P(A_1) = \underbrace{p \dots p}_{k} \underbrace{q \dots q}_{n - k} = p^k q^{n - k}\]

    Остальные благоприятные исходы отличаются лишь расстановкой \(k\) успехов по \(n\) местам, а их вероятности будут те же самые.
\end{proof}

Выясним, при каком значении \(k\) вероятность предшествующего числа успехов \(k - 1\) будет не более, чем вероятность \(k\) успехов, т.е. \(P_n(k) \geq P_n(k - 1)\)

\begin{align*}
    P_n(k - 1)                              & \leq P_n(k)                          \\
    \binom{n}{k - 1} p^{k - 1}q^{n - k + 1} & \leq \binom{n}{k} p^k q^{n - k}      \\
    \frac{n!}{(k - 1)!(n - k + 1)!} q       & \leq \frac{n!}{k!(n - k)!} p         \\
    \frac{k!}{(k - 1)!} q                   & \leq \frac{(n - k + 1)!}{(n - k)!} p \\
    k(1 - p)                                & \leq (n - k + 1) p                   \\
    k - kp                                  & \leq np - kp + p                     \\
    np + p - 1 \leq k                       & \leq np + p
\end{align*}

\begin{enumerate}
    \item \(np\) --- целое. Тогда \(np + p\) --- не целое и \(k = np\) --- наибольшее искомое \(k\)
    \item \(np + p\) --- не целое. Тогда \(k = [np + p]\)
    \item \(np + p\) --- целое. Тогда \(np + p - 1\) --- целое и \(P_n(k - 1) = P_n(k)\) и \(k = np + p\) или \(k = np + p - 1\)
\end{enumerate}

\subsection{Локальная формула Муавра-Лапласа}

\begin{remark}
    Локальность формулы означает, что мы её применям, чтобы найти вероятность некоторого числа успехов.
\end{remark}

\[P_n(v_n = k) \approx \frac{1}{\sqrt{n p q}} \varphi(x) \text{ , где } \varphi(x) = \frac{1}{\sqrt{2\pi}}e^{ -\frac{x^2}{2}}, x = \frac{k - np}{\sqrt{npq}} \]

\(\varphi\) называется функцией Гаусса.

\begin{prop}\itemfix
    \begin{itemize}
        \item \(\varphi( - x) = \varphi(x)\)
        \item При \( x > 5\) \(\varphi(x) \approx 0\)
    \end{itemize}
\end{prop}

\subsection{Интегральная формула Лапласа}

\begin{remark}
    Эта формула применяется, если искомое число успехов лежит в некотором диапазоне.
\end{remark}

\[P_n(k_1 \leq v_n \leq k_2) \xrightarrow{n \to +\infty} \Phi(x_2) - \Phi(x_1) \text{ , где } \Phi(x) = \frac{1}{\sqrt{2\pi}} \int_0^x e^{- \frac{t^2}{2}dt}\]
\[x_1 = \frac{k_1 - np}{\sqrt{npq}}, x_2 = \frac{k_2 - np}{\sqrt{npq}}\]

\begin{prop}\itemfix
    \begin{itemize}
        \item \(\Phi( - x) = -\Phi(x)\)
        \item При \( x > 5\) \(\Phi(x) \approx 0.5\)
    \end{itemize}
\end{prop}

\begin{remark}
    В некоторых источниках под функцией Лапласа подразумевается несколько иная функция, чаще всего
    \[F_0(X) = \int_{ -\infty}^x e^{- \frac{t^2}{2}dt}\]
    Несложно заметить, что \(F_0(x) = 0.5 + \Phi(x)\)
\end{remark}

Мы применяем эти формулы при \(n \geq 100\) и \(p, q \geq 0.1\)

\begin{example}
    Вероятность попадания стрелка в цель при одном выстреле \(0.8\). Стрелок сделал \(400\) выстрелов. Найти вероятность того, что:
    \begin{enumerate}
        \item Произошло ровно \(330\) попаданий.
        \item Произошло от \(312\) до \(336\) попаданий.
    \end{enumerate}

    \begin{enumerate}
        \item \(k = 400, p = 0.8, q = 0.2, k = 330\)
              \[x = \frac{330 - 400\cdot 0.8}{\sqrt{400\cdot 0.8\cdot 0.2}} = \frac{10}{8} = 1.25\]
              \[P_{400}(320) \approx \frac{1}{\sqrt{400\cdot 0.8\cdot 0.2}} \frac{1}{\sqrt{2\pi}}e^{ - \frac{1.25^2}{2}} \approx 0.0228\]

        \item \(k = 400, k_1 = 312, k_2 = 336, p = 0.8, q = 0.2\)
              \[x_1 = \frac{332 - 400\cdot 0.8}{\sqrt{400\cdot 0.8\cdot 0.2}} = \frac{312 - 320}{8} =- 1\]
              \[x_2 = \frac{336 - 320}{8} = 2\]
              \[P_{400}(312 \leq v_n \leq 336) \approx \Phi(2) - \Phi( - 1) = \Phi(2) + \Phi(1) \approx 0.8285\]
    \end{enumerate}
\end{example}

\subsection{Вероятность отклонения относительно частоты от вероятности события}

Пусть \(p\) --- вероятность события \(A\), \(\frac{n_A}{n}\) --- частота \(A\). По интегральной формуле Лапласа найдём вероятность того, что частота отклонится от \(p\) не больше, чем на \(\varepsilon\):
\begin{align*}
    P\left(\left|\frac{n_A}{n} - p\right| \leq \varepsilon\right) & = P( - \varepsilon \leq \frac{n_A}{n} - p \leq \varepsilon)                                                      \\
                                                                  & = P( - n\varepsilon \leq n_A - np \leq n\varepsilon)                                                             \\
                                                                  & = P( np - n\varepsilon \leq n_A \leq np + n\varepsilon)                                                          \\
                                                                  & \approx \Phi\left( \frac{n\varepsilon}{\sqrt{npq}} \right) - \Phi\left( -\frac{n\varepsilon}{\sqrt{npq}} \right) \\
                                                                  & = 2\Phi\left( \frac{n\varepsilon}{\sqrt{npq}} \right)
\end{align*}

Итого:
\[P\left(\left|\frac{n_A}{n} - p\right| \leq \varepsilon\right) \approx 2\Phi\left( \frac{\sqrt{n}\varepsilon}{\sqrt{pq}} \right)\]

\subsection{Закон больших чисел Бернулли}

\[P\left(\left|\frac{n_A}{n} - p\right| \leq \varepsilon\right) \xrightarrow{n \to +\infty} 2\Phi\left( \frac{\sqrt{n}\varepsilon}{\sqrt{pq}} \right)\]

При \(n \to +\infty\) : \(\frac{\sqrt{n}\varepsilon}{\sqrt{pq}} \to +\infty\) и \(\Phi\left( \frac{\sqrt{n}\varepsilon}{\sqrt{pq}} \right) \to 0.5\), поэтому \(P\left(\left|\frac{n_A}{n} - p\right| \leq \varepsilon\right) \to 2\cdot 0.5 = 1\), т.е.:

\[\lim_{n \to +\infty} P\left(\left|\frac{n_A}{n} - p\right| \leq \varepsilon\right) = 1\]
Эта формула называется законом больших чисел Бернулли.

\chapter{13 марта}

\begin{remark}
    Конспект этой лекции написан по другому конспекту, т.к. записи лекции нет.
\end{remark}

\begin{definition}
    Отображение \(k \mapsto \binom{n}{k} q^{n - k}p^k\), где \(0 \leq k \leq n\) называется \textbf{биноминальным распределением} с параметрами \(n\) и \(p\).
\end{definition}

\begin{obozn}
    \(B(n,p)\) или \(B_{n, p}\)
\end{obozn}

\subsection{Схема до первого успешного испытания}

Пусть проводится бесконечная серия испытаний, которая заканчивается после первого успеха. Номер такого успеха обозначается \(\tau\).

\begin{theorem}
    \(P(\tau = k) = q^{n - 1}p\)
\end{theorem}
\begin{proof}
    \[P(\tau = k) = P(\underbrace{\text{НН}\dots\text{Н}}_{k - 1}\text{У}) = q^{k-1}p\]
\end{proof}

\begin{definition}
    Отображение \(k \mapsto q^{k - 1}p\) при \(1 \leq k < +\infty\) называется \textbf{геометрическим распределением} с параметром \(p\).
\end{definition}

\begin{obozn}
    \(G_p\) или \(G(p)\)
\end{obozn}

\begin{remark}
    Это распределение обладает свойством ``отсутствие последействия'' или нестарения, т.е. знание о том, что у вас не было успеха в течение \(n\) испытаний, никак не влияет на распределение оставшегося числа испытаний.
\end{remark}

\begin{theorem}
    \(p(\tau = k) = q^{k - 1}p\). Тогда
    \[\forall n,k\in\N \ \ P(\tau > k + n\ |\ \tau > n) = p(\tau > k)\]
\end{theorem}
\begin{proof}
    \[P(\tau > n) = P(\underbrace{\text{НН}\dots\text{Н}}_{m})= q^m\]

    По формуле полной вероятности:
    \begin{align*}
        P(\tau > n + k\ |\ \tau > n) & = \frac{P(\tau > n + k \cap \tau > n)}{P(\tau > k)} \\
                                     & = \frac{P(\tau > n + k)}{P(\tau > n)}               \\
                                     & = \frac{q^{n + k}}{q^n}                             \\
                                     & = q^k                                               \\
                                     & = P(\tau > k)
    \end{align*}
\end{proof}

\begin{remark}
    Аналогично \(P(\tau = n + k\ |\ \tau > n) = P(\tau = k)\)
\end{remark}

\subsection{Испытания с несколькими исходами}

Пусть мы выполняем \(n\) испытаний, и при каждом из них может произойти один из \(m\) несовместных исходов.
\begin{obozn}
    \(p_i\) --- вероятность \(i\)-го исхода при одном испытании.
\end{obozn}

\begin{theorem}
    Вероятность того, что при \(n\) испытаниях первый исход появится \(n_1\) раз, второй \(n_2\) раз, \(m\)-тый исход \(n_m\) раз:
    \[P(n_1 \dots n_m) = \frac{n!}{n_1!n_2! \dots n_m!} \cdot p_1^{n_1} p_2^{n_2} \dots p_m^{n_m}\]
\end{theorem}

\begin{remark}
    При \(m = 2\) эта теорема эквивалентна формуле Бернулли.
\end{remark}

\begin{proof}
    Рассмотрим следующий благоприятный исход \(A_1\):
    \[\underbrace{1\dots 1}_{n_1} \underbrace{2\dots 2}_{n_2} \dots \underbrace{m\dots m}_{n_m}\]
    \[P(A_1) = p_1^{n_1} p_2^{n_2} \dots p_m^{n_m}\]

    Остальные благоприятные исходы имеют ту же вероятность и равны с точностью до перестановки. Всего таких исходов
    \[\binom{n}{n_1}\binom{n - n_1}{n_2}\binom{n - n_1 - n_2}{n_3} \dots \binom{n_m}{n_m} = \frac{n!}{n_1!n_2! \dots n_m!}\]
\end{proof}

\subsection{Урновая схема}

В урне \(N\) шаров, из них \(K\) белых и \(N - K\) чёрных. Из неё выбрали \(n\) шаров без учета порядка.

\begin{enumerate}
    \item Схема с возвратом.

          Вероятность выбрать белый шар не меняется и равна \(\frac{K}{N}\). Тогда \(P_n(k) = \binom{n}{k}p^k(1 - p)^n\) --- опять биноминальное распределение.

    \item Схема без возврата.

          Тогда \(P_{N,K}(n, k) = \cfrac{\binom{N}{k} \cdot \binom{N - k}{n - k}}{\binom{N}{n}} \)
\end{enumerate}

\begin{definition}
    Отображение \(k \mapsto \cfrac{\binom{K}{k}\cdot \binom{N - K}{n - k}}{\binom{N}{n}}\) при \(k < K\) называется \textbf{гипергеометрическим распределением}.
\end{definition}

\begin{theorem}
    Если \(N \to +\infty\) и \(K \to +\infty\) так, что \(\frac{K}{N} \to p\in(0,1)\), \(n\) и \(0 \leq k \leq n\) фиксированы, то \(P_{N,K}(n,k) = \cfrac{\binom{K}{k}\binom{N - K}{n - k}}{\binom{N}{n}} \to \binom{n}{k}p^k q^{n - k}\)

    \label{урна бином}
\end{theorem}

\begin{lemma}
    \(\binom{K}{k} \sim \frac{K^k}{k!} \), где \(K \to +\infty\), \(k = \const\)
\end{lemma}
\begin{proof}
    \begin{align*}
        \binom{K}{k} & = \frac{K!}{k!(K - k)!}                                                                                                             \\
                     & = \frac{K\cdot(K - 1)\dots (K - k + 1)}{k^k}\frac{K^k}{k!}                                                                          \\
                     & = 1\cdot \left( 1 - \frac{1}{k} \right)\left( 1 - \frac{2}{k} \right) \dots \left( 1 - \frac{k - 1}{k} \right) \cdot \frac{K^k}{k!} \\
                     & \sim \frac{K^k}{k!}
    \end{align*}
\end{proof}

\begin{proof}[Доказательство \ref{урна бином}]
    \begin{align*}
        P_{N, K}(n, k) & = \frac{\binom{K}{k} \binom{N - K}{n - k}}{\binom{N}{n}}                         \\
                       & \xrightarrow[n \to +\infty]{\substack{\text{к каждому}                           \\ \text{применили} \\ \text{формулу}}} \frac{K^k}{k!} \frac{(N-K)^{n-k}}{(n-k)!} \frac{n!}{N^n}   \\
                       & = \frac{n!}{k!(n - k)!} \frac{K^k}{N^k} \frac{(N - k)^{n - k}}{N^{n - k}}        \\
                       & = \binom{N}{k} \left( \frac{k}{N} \right) \left( 1 - \frac{K}{N} \right)^{n - k} \\
                       & \xrightarrow{N \to +\infty} \binom{n}{k} p^k (1 - p)^{n - k}
    \end{align*}
\end{proof}

\subsection{Теорема Пуассона для схемы Бернулли}

Пусть вероятность успеха при \(n\)-том испытании \(p_n\) и при этом \(n p_n\xrightarrow{n \to +\infty}\lambda =\const\)

\textcolor{red}{Не дописано}

\end{document}
