\chapter{13 сентября}

\section{Точечные оценки}


%<*1>
Пусть имеется выборка объема \(n\): \(X = \begin{pmatrix}
    X_1 & \dots & X_n
\end{pmatrix}\)
\begin{definition}
    \textbf{Статистикой} называется измеримая функция \(\theta^* = \theta^*(X_1, \dots, X_n)\).
\end{definition}

Пусть требуется найти значение параметра \(\theta\) случайной величины \(X\) по данной выборке. Оценку будем считать с помощью некоторой статистики \(\theta^*\).

\subsection{Свойства статистических оценок}

\subsubsection{Состоятельность}

\begin{definition}
    Статистика \(\theta^* = \theta^*(X_1, \dots, X_n)\) называется \textbf{состоятельной оценкой} параметра \(\theta\), если:
    \[\theta^* \xrightarrow[n \to \infty]{P} \theta\]
\end{definition}

\subsubsection{Несмещённость}

\begin{definition}
    Статистика \(\theta^* = \theta^*(X_1, \dots, X_n)\) называется \textbf{несмещенной оценкой} параметра \(\theta\), если
    \[\E \theta^* = \theta\]
\end{definition}

\begin{remark}
    То есть с равной вероятностью можем ошибиться как в меньшую, так и в большую сторону. Нет систематической ошибки.
\end{remark}

\begin{definition}
    Статистика \(\theta^* = \theta^*(X_1, \dots, X_n)\) называется \textbf{асимптотически несмещенной оценкой} параметра \(\theta\), если
    \[\E \theta^* \xrightarrow[n \to \infty ]{} \theta\]
\end{definition}

\begin{remark}
    То есть при достаточно большом объеме выборки ошибка исчезает, но при малом она может существовать.
\end{remark}

\subsubsection{Эффективность}

\begin{definition}
    Оценка \(\theta_1^*\) \textbf{не хуже} оценки \(\theta_2^*\), если
    \[\E (\theta_1^* - \theta)^2 \leq \E (\theta_2^* - \theta)^2\]
    или, если обе оценки несмещенные,
    \begin{align*}
        \E (\theta_1^* - \theta)^2        & \leq \E (\theta_2^* - \theta)^2        \\
        \E (\theta_1^* - \E \theta_1^*)^2 & \leq \E (\theta_2^* - \E \theta_2^*)^2 \\
        \D \theta_1^*                     & \leq \D \theta_2^*
    \end{align*}
\end{definition}

\begin{definition}
    Оценка \(\theta^*\) называется \textbf{эффективной}, если она не хуже всех остальных оценок.
\end{definition}

\begin{theorem}
    Не существует эффективной оценки в классе всех возможных оценок.
\end{theorem}

\begin{theorem}
    В классе несмещённых оценок существует эффективная оценка.
\end{theorem}
%</1>

\subsection{Точечные оценки моментов}

%<*2.1>
\begin{definition}
    \textbf{Выборочным средним} \(\overline{X_B}\) называется величина
    \begin{myemph}
        \overline{X_B} = \frac{1}{n} \sum_{i=1}^{n} X_i
    \end{myemph}
\end{definition}

\begin{definition}
    \textbf{Выборочной дисперсией} \(\D_B\) называется величина
    \begin{myemph}
        \D_B = \frac{1}{n} \sum_{i=1}^{n} (X_i - \overline{X_B})^2
    \end{myemph}
\end{definition}

\begin{definition}
    \textbf{Исправленной выборочной дисперсией} \(S^2\) называется величина
    \begin{myemph}
        S^2 = \frac{n}{n - 1} \D_B
    \end{myemph}
    или
    \begin{myemph}
        S^2 = \frac{1}{n - 1} \sum_{i=1}^{n} (X_i - \overline{X_B})^2
    \end{myemph}
\end{definition}

\begin{definition}
    \textbf{Выборочным средним квадратическим отклонением} называется величина
    \begin{myemph}
        \sigma_B = \sqrt{\D_B}
    \end{myemph}
\end{definition}

\begin{definition}
    \textbf{Исправленным выборочным средним квадратическим отклонением} называется величина
    \begin{myemph}
        S = \sqrt{S^2}
    \end{myemph}
\end{definition}

\begin{definition}
    \textbf{Выборочным \(k\)-тым моментом} называется величина
    \begin{myemph}
        \overline{X^k} = \frac{1}{n}\sum_{i=1}^{n} X_i^k
    \end{myemph}
\end{definition}
%</2.1>

\begin{definition}
    \textbf{Модой} \(M_0^*\) вариационного ряда называется варианта с наибольшей частотой:
    \begin{myemph}
        M_0^* = X_i : n_i = \max_{1 \leq j < n} n_j
    \end{myemph}
\end{definition}

\begin{definition}
    \textbf{Медианой} \(M_e^*\) вариационного ряда называется значение варианты в середине ряда:
    \begin{enumerate}
        \item Если \(n = 2k - 1\), то \(M_e^* = X_k\)
        \item Если \(n = 2k\), то \(M_e^* = \frac{X_k + X_{k + 1}}{2}\)
    \end{enumerate}
\end{definition}

\begin{center}
    \begin{tabular}{Lll}\toprule
        \multirow{2}{*}{Величина} & \multicolumn{2}{c}{Команда в Excel}              \\
        \cmidrule{2-3}
                                  & Русский                             & Английский \\
        \midrule
        \overline{X_B}            & СРЗНАЧ                              & AVERAGE    \\
        \D_B                      & ДИСПР                               & VARP       \\
        S^2                       & ДИСП                                & VAR        \\
        \sigma_n                  & СТАНДОТКЛОНП                        & STDEVP     \\
        S                         & СТАНДОТКЛОН                         & STDEV      \\
        M_0^*                     & МОДА                                & MODE       \\
        M_e^*                     & МЕДИАНА                             & MEDIAN     \\
        \bottomrule
    \end{tabular}
\end{center}

%<*2.2>
\begin{theorem}
    Выборочное среднее \(\overline{X_B}\) является несмещенной состоятельной оценкой для математического ожидания, то есть:
    \begin{enumerate}
        \item \(\E \overline{X_B} = \E X = a\) --- несмещенность
        \item \(\overline{X_B} \xrightarrow[n \to \infty ]{P} \E X\) --- состоятельность
    \end{enumerate}
\end{theorem}
\begin{proof}\itemfix
    \begin{enumerate}
        \item \[\E \overline{X} = \E \left( \frac{1}{n} \sum_{i=1}^{n} X_i \right) = \frac{1}{n} \sum_{i=1}^{n} \E X_i = \frac{1}{n} \cdot n \E X_i = \E X\]
        \item \[\overline{X} = \frac{\sum_{i=1}^{n} X_i}{n} \xrightarrow[n \to \infty ]{P} \E X\]
              Это верно по закону больших чисел.
    \end{enumerate}
\end{proof}

\begin{theorem}
    \label{оценка момента}
    Выборочный \(k\)-тый момент является несмещенной состоятельной оценкой для теоретического \(k\)-того момента, то есть:
    \begin{enumerate}
        \item \(\E \overline{X^k} = \E X^k\)
        \item \(\overline{X^k} \xrightarrow[]{P} \E X^k\)
    \end{enumerate}
\end{theorem}
\begin{proof}
    Следует из предыдущей теоремы, если в качестве случайной величины взять \(X^k\).
\end{proof}

\begin{theorem}\itemfix
    \begin{itemize}
        \item \(\D_B\) --- смещённая состоятельная оценка дисперсии
        \item \(S^2\) --- несмещённая состоятельная оценка дисперсии
    \end{itemize}
\end{theorem}
\begin{proof}
    \[\D_B = \frac{1}{n} \sum_{i=1}^{n} (X_i - \overline{X})^2 = \overline{X^2} - (\overline{X})^2\]
    \begin{align*}
        \E \D_B                                                                     & =                                                       \\
        \E (\overline{X^2} - (\overline{X})^2)                                      & =                                                       \\
        \E \overline{X^2} - \E (\overline{X})^2                                     & \stackrel{\mathrlap{\text{по \ref{оценка момента}}}}{=} \\
        \E X^2 - \E (\overline{X})^2                                                & =                                                       \\
        \E X^2 - (\D \overline{X} + (\E \overline{X})^2)                            & =                                                       \\
        \E X^2 - (\E \overline{X})^2 - \D \overline{X}                              & =                                                       \\
        (\E X^2 - (\E X)^2) - \D \overline{X}                                       & =                                                       \\
        \D X - \underbrace{\D \overline{X}}_{\mathclap{\text{величина отклонения}}} & =                                                       \\
        \D X - \D \left( \frac{1}{n} \sum_{i=1}^{n} X_i \right)                     & =                                                       \\
        \D X - \frac{1}{n^2} \sum_{i=1}^{n} \D X_i                                  & =                                                       \\
        \D X - \frac{1}{n^2} \cdot n \D X                                           & =                                                       \\
        \D X - \frac{1}{n} \D X                                                     & =                                                       \\
        \frac{n - 1}{n} \D X                                                        & \neq \D X
    \end{align*}
    \[\E S^2 = \E \left( \frac{n}{n -1} \D_B \right) = \frac{n}{n - 1} \cdot \frac{n - 1}{n} \D X = \D X\]
    \[\D_B = \overline{X^2} - (\overline{X})^2 \xrightarrow[]{P} \E X^2 - (\E X)^2 = \D X\]
    \[S^2 = \frac{n}{n - 1} \D_B \xrightarrow[]{P} \underbrace{\frac{n}{n - 1}}_{ \to 1} \D X\]
\end{proof}

\begin{remark}
    \(\D_B\) --- асимптотически несмещённая оценка, т.к. при \(n \to \infty\), \(\frac{n - 1}{n} \to 1\). Таким образом, при большой\footnote{\(n \geq 100\), например.} выборке можно игнорировать смещённость.
\end{remark}
%</2.2>

\subsection{Метод моментов}

%<*3>
Изобретен Карлом Пирсоном.

Пусть имеется выборка \((X_1 \dots X_n)\) неизвестного распределения, при этом известен тип\footnote{Нормальное, показательное и т.д.} распределения. Пусть этот тип определяется \(k\) неизвестными параметрами \(\theta_1 \dots \theta_k\). Теоретическое распределение задает теоретические \(k\)-тые моменты. Например, если распределение непрерывное, то оно задается плотностью \(f(X, \theta_1 \dots \theta_k)\) и
\[m_k = \int_{ - \infty}^{ +\infty} X^k f(x, \theta_1 \dots \theta_k) dx = h_k(\theta_1 \dots \theta_k)\]
Метод моментов состоит в следующем: вычисляем выборочные моменты и подставляем их в эти равенства вместо теоретических. В результате получаем систему уравнений:
\[\begin{cases}
        \overline{X} = h_1(\theta_1 \dots \theta_k)   \\
        \overline{X^2} = h_2(\theta_1 \dots \theta_k) \\
        \vdots                                        \\
        \overline{X^k} = h_k(\theta_1 \dots \theta_k)
    \end{cases}\]
Решив эту систему, мы получим оценки на \(\theta_1 \dots \theta_k\). Эти оценки будут состоятельными\footnote{Если не придумывать специально плохие примеры}, но смещёнными.

\begin{example}
    Пусть \(X \in U(a, b), a < b\). Обработав статданные, получили оценки первого и второго момента: \(\overline{X} = 2.25; \overline{X^2} = 6.75\)
\end{example}
\begin{solution}
    Плотность \(f(x) = \begin{cases}
        0,               & x < a           \\
        \frac{1}{b - a}, & a \leq x \leq b \\
        0,               & x > b
    \end{cases}\)
    \[\E X = \int_a^b x f(x) dx = \int_a^b \frac{x}{b - a} = \frac{1}{b - a} \cdot \frac{x^2}{2}\Big|_a^b = \frac{b^2 - a^2}{2(b - a)} = \boxed{\frac{a + b}{2}}\]
    \[\E X^2 = \int_a^b x^2 \cdot \frac{1}{b - a} dx = \frac{1}{b - a} \cdot \frac{x^3}{3} \Big|_a^b = \frac{b^3 - a^3}{3(b - a)} = \boxed{\frac{a^2 + ab + b^2}{3}}\]
    \[\begin{cases}
            2.25 = \frac{a + b}{2} \\
            6.75 = \frac{a^2 + ab + b^2}{3}
        \end{cases}\]
    \[\begin{cases}
            a + b = 4.5 \\
            a^2 + ab + b^2 = 20.25
        \end{cases}\]
    \[\begin{cases}
            a + b = 4.5 \\
            ab = 0
        \end{cases}\]
    \[\begin{cases}
            a = 0 \\
            b = 4.5
        \end{cases}\]
\end{solution}
%</3>
