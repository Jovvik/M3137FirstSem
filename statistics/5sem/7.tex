\chapter{18 октября}

На прошлой лекции мы обсуждали проверку статистических гипотез, эта лекция будет посвящена основному набору оных.

\subsection{Критерии для проверки гипотез о распределении}

\subsubsection{Критерий \(\chi^2\) для параметрической гипотезы}

Этот критерий самый популярный.

Пусть дана выборка \((X_1 \dots X_n)\) неизвестного распределения \(\mathcal{F}\). Проверяется основная сложная гипотеза \(H_0 : \mathcal{F} \in \mathcal{F}_\theta\), т.е. \(\mathcal{F}\) принадлежит классу распределений \(\mathcal{F}_\theta\), параметризованное набором из \(m\) параметров: \(\theta = (\theta_1 \dots \theta_m)\).

Пусть \(\hat{\theta} = (\hat{\theta}_1 \dots \hat{\theta}_m)\) --- оценка этих параметров методом максимального правдоподобия. Пусть выборка разбита на \(k\) интервалов \(A_1 \dots A_k\), где \(A_i = [a_{i-1}, a_i)\). Пусть \(n_i\) --- соответствующие экспериментальные частоты попадания в интервал \(A_i\), \(p_i\) --- соответствующие теоретические вероятности попадания в эти интервалы при распределении \(\mathcal{F}_{ \hat{\theta}}\)

\begin{remark}
    \(p_i = \mathcal{F}_{ \hat{\theta}}(a_i) - \mathcal{F}_{ \hat{\theta}}(a_{i-1})\)
\end{remark}

Тогда \(n_i' = np_i\) --- теоретические частоты попадания в \(A_i\).

В качестве статистики критерия берётся:
\[K = \sum_{i=1}^{k} \frac{(n_i - n_i')^2}{n_i'} = \sum_{i=1}^{k} \frac{n_i^2}{n_i'} - n\]

\begin{theorem}[Фишера]
    Если гипотеза \(H_0 : \mathcal{F} \in \mathcal{F}_\theta\) верна, то
    \[K = \sum_{i=1}^{k} \frac{(n_i - n_i')^2}{n_i'} \in H_{k - m - 1}\]
    , т.е. \(K\) имеет распределение \(\chi^2\) с \(k - m - 1\) степенями свободы, где \(k\) --- число интервалов и \(m\) --- число параметров, задающих распределение.
\end{theorem}
\begin{proof}
    Использует многомерное нормальное распределение.
\end{proof}

Критерий используется следующим образом: для заданного уровня значимости \(\alpha\) находим критическую точку \(t_k\), такую что \(P(\chi^2_{k - m - 1} \geq t_k) = \alpha\). Тогда критерий имеет вид:
\[\begin{cases}
        H_0, & K < t_k    \\
        H_1, & K \geq t_k
    \end{cases}\]

\begin{remark}
    \(t_k = \text{ХИ2.ОБР.ПХ}(\alpha, k - m - 1)\)
\end{remark}

\begin{remark}
    Частота интервалов должна быть \( \geq 5\). Если нет, то объединяем соседние интервалы.
\end{remark}

\begin{remark}
    Желательно выборку разбить на большое число равнонаполненных интервалов.
\end{remark}

\begin{example}
    Имеется выборка в виде частотного вариационного ряда объёма \(n = 120 : (5.2 \dots 82.8)\). При разбиении её на \(8\) интервалов получили интервальный ряд:
    \begin{center}
        \begin{tabular}{LLL}
            \toprule{}
            A_i            & n   & n_i \\ \midrule
            {}[5.2; 7.4)   & 12  & 15  \\
            {}[7.4; 9.6)   & 17  & 15  \\
            {}[9.6; 11.8)  & 14  & 15  \\
            {}[11.8, 14)   & 13  & 15  \\
            {}[14; 16.2)   & 18  & 15  \\
            {}[16.2; 18.4) & 14  & 15  \\
            {}[18.4; 20.6) & 13  & 15  \\
            {}[20.6; 22.6) & 11  & 15  \\
            \Sigma         & 120 & 120 \\
            \bottomrule
        \end{tabular}
    \end{center}

    Проверим гипотезу о равномерности распределения при уровне значимости \(\alpha = 0.05\) : \(H_0 : \mathcal{F} \in U(a; b), H_1 : \mathcal{F} \notin U(a; b)\)

    \(\hat{a} = X_{\min} = 5.2, \hat{b} = X_{\max} = 82.8, n_i = \frac{120}{8} = 15\) --- теоретические частоты.

    \(\chi_{\text{набл}}^2 = \sum_{i=1}^{8} \frac{(n_i - n_i')^2}{n_i'} = 3.2\)

    \(\alpha = 0.05\), число степеней свободы: \(k - m - 1 = 8 - 2 - 1 = 5, t_k(0.05; 5) = 11.07, \chi^2_{\text{набл}} = 3.2 < 11.07\), гипотеза о равномерном распределении принимается.
\end{example}

\subsubsection{Критерий \(\chi^2\)}

Проверяется основная (простая) гипотеза \(H_0 : \mathcal{F} = \mathcal{F}_\theta\), где \(\mathcal{F}_\theta\) --- распределение известного типа с известными параметрами, против \(H_1 : \mathcal{F} \neq \mathcal{F}_\theta\). В качестве статистики берётся та же самая функция
\[K = \sum_{i=1}^{k} \frac{(n_i - n_i')^2}{n_i'}\]

\begin{theorem}[Парона\?]
    Если гипотеза \(H_0\) верна, то
    \[K = \sum_{i=1}^{k} \frac{(n_i - n_i')^2}{n_i'} \in H_{k - 1}\]
\end{theorem}

% Т.к. степеней свободы больше, критическая точка дальше. На первый взгляд получается, что вероятность принять эту 

\subsubsection{Критерий Колмогорова}

Приведён по историческим причинам.

Пусть имеется выборка \((X_1 \dots X_n)\) неизвестного распределения \(\mathcal{F}\). Проверяется простая гипотеза \(H_0 : \mathcal{F} = \mathcal{F}_1\) против \(H_1 : \mathcal{F} \neq \mathcal{F}_1\). Пусть \(F_1(x)\) --- непрерывная функция распределения \(\mathcal{F}_1\). Тогда применяем критерий:
\[K = \sqrt{n} \sup_x |F^*(x) - F_1(x)|\]
, где \(F^*(x)\) --- выборочная функция распределения.

\begin{theorem}
    Если гипотеза \(H_0\) верна, то
    \[K = \sqrt{n} \sup_x |F^*(x) - F_1(x)| \xrightrightarrows{n \to \infty} \mathcal{K}\]
    , где \(\mathcal{K}\) --- распределение Колмогорова с функцией распределения \(F_{\mathcal{K}}(x) = \sum_{j=- \infty }^{\infty} ( - 1)^j e^{ - 2j^2x^2}\).
\end{theorem}

Для уровня значимости находим \(t_k\) и дальше как обычно.

В некоторых статистических пакетах это распределение есть, в Excel --- нет. Исторически оно не распространилось.

Недостаток этого критерия в том, что он не применим в дискретном случае.

\subsection{Критерии для проверки однородности}

Мы хотим узнать, случайна ли эта выборка, или её кто-то неправильно собрал данные.

\subsubsection{Критерий Колмогорова-Смирнова}

Также используется редко.

Пусть имеются две независимых выборки \((X_1 \dots X_n)\) и \((Y_1 \dots Y_m)\) объёмов \(n\) и \(m\) соответственно неизвестных непрерывных распределений \(\mathcal{F}\) и \(\mathcal{G}\). Проверяется гипотеза \(H_0 : \mathcal{F} = \mathcal{G}\) против гипотезы \(H_1 : \mathcal{F} = \mathcal{G}\). В качестве статистики берётся:
\[K = \sqrt{\frac{nm}{n + m}} \sup_x |F^*(x) - G^*(x)|\]
, где \(F^*(x)\) и \(G^*(x)\) --- соответствующие выборочные функции распределения.

\begin{theorem}
    Если гипотеза \(H_0\) верна, то
    \[K = \sqrt{\frac{nm}{n + m}} \sup_x |F^*(x) - G^*(x)| \xrightrightarrows[m \to \infty]{n \to \infty} \mathcal{K}\]
\end{theorem}

\begin{remark}
    Чаще всего в случае нормальных распределений используются критерии Фишера и Стьюдента. Сначала применяем критерий Фишера и если он не отвергает основную гипотезу, то применяем критерий Стьюдента.

    Ещё часто применяется ранговый критерий Уилкоксона-Манна-Уитни. Мы его не рассмотрим, но общая идея в следующем: рассматривается только одна выборка и если выборка составлялась не случайно, то порядок возрастания/убывания нарушен.
\end{remark}

\subsubsection{Критерий Фишера}

Пусть имеются две независимых выборки \((X_1 \dots X_n)\) и \((Y_1 \dots Y_m)\) объёмов \(n\) и \(m\) соответственно из нормальных распределений \(N(a_1, \sigma_1^2)\) и \(N(a_2, \sigma_2^2)\). Проверяется гипотеза \(H_0 : \sigma_1 = \sigma_2\) против гипотезы \(H_1 : \sigma_1 \neq \sigma_2\). В качестве статистики берётся:
\[K = \frac{S_x^2}{S_y^2}\]
, где \(S_x^2, S_y^2\) --- соответствующие исправленные дисперсии, причём \(S_x^2 \geq S_y^2\)

\begin{theorem}
    Если \(H_0\) верна, то \(\frac{S_x^2}{S_y^2} \in F(n - 1, m - 1)\) --- распределение Фишера с \(n - 1, m - 1\) степенями свободы.
\end{theorem}
\begin{proof}
    По пункту 3 основной теоремы \(\frac{(n - 1)S^2}{\sigma^2} \in H_{n-1}\) или \(\frac{S^2}{\sigma^2} \in \frac{\chi_{n - 1}^2}{n - 1}\).

    При \(\sigma_1 = \sigma_2 = \sigma\):
    \[\frac{S_x^2}{S_y^2} = \frac{S_x^2}{\sigma^2} \cdot \frac{\sigma^2}{S_y^2} = \frac{\chi_{n-1}^2}{n - 1} \cdot \frac{m - 1}{\chi_{m - 1}^2} \defeq F(n - 1, m - 1)\]
\end{proof}

Критерий по статистике очевиден.

\begin{remark}
    При \(H_1 : \sigma_1 \neq \sigma_2\), т.е. \(\sigma_1 > \sigma_2, K = \frac{S_x^2}{S_y^2} = \frac{\sigma_1^2}{\sigma_2^2} > 1\)

    При \(H_0\) выполнено \(K \to 1\).
\end{remark}

\subsubsection{Критерий Стьюдента}

Пусть имеются две независимых выборки \((X_1 \dots X_n)\) и \((Y_1 \dots Y_m)\) объёмов \(n\) и \(m\) соответственно из нормальных распределений \(N(a_1, \sigma^2)\) и \(N(a_2, \sigma^2)\) с одинаковой дисперсией \(\sigma^2\). Проверяется гипотеза \(H_0 : a_1 = a_2\) против гипотезы \(H_1 : a_1 \neq a_2\).

\begin{theorem}
    Случайная величина
    \[\sqrt{\frac{nm}{n + m}} \frac{(\overline{X} - a_1) - (\overline{Y} - a_2)}{\sqrt{\frac{(n - 1)S_x^2 + (m - 1)S_y^2}{n + m - 2}}} \in T_{n + m - 2}\]
    , где \(T_{n + m - 2}\) --- распределение Стьюдента с \(n + m - 2\) степенями свободы. Это не зависит от того, верна гипотеза или нет.
\end{theorem}

В качестве статистики берётся:
\[K = \sqrt{\frac{nm}{n + m}} \frac{\overline{X} - \overline{Y}}{\sqrt{\frac{(n - 1)S_x^2 + (m - 1)S_y^2}{n + m - 2}}}\]

Из теоремы видим, что если \(H_0\) верна, то \(K \in T_{n + m - 2}\), если нет, то \(K \xrightarrow[n \to \infty]{m \to \infty} \infty\).

Критерий: пусть \(t_k\) --- квантиль распределения Стьюдента \(|T_{n + m - 2}|\) уровня значимости \(\alpha\).
\[\begin{cases}
        H_0 : a_1 = a_2,    & K < t_k    \\
        H_1 : a_1 \neq a_2, & K \geq t_k
    \end{cases}\]

Существует масса других критериев, но все они строятся похожим образом.
